{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This script is used to automatically generate datasets formatted to be interpretable by DeepLabCut.\n",
    "\n",
    "**WARNING :** Restrict the **Colony size** to a **maxmimum of 20 individuals**, otherwise the generation of datasets will fail, as the number of necessary columns would exceed the 64kb Metadata limit of the exported HDF5 file!\n",
    "\n",
    "Ensure, that your **GPU** has sufficient **memory** for the chosen resolution! \n",
    "\n",
    "E.g. at 1024 px X 1024 px, training on an RTX 2080 Ti, set the **batchsize** to 4 in the **pose_cfg.yaml** file of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 files...\n",
      "reading ColonieInfo.csv\n",
      "Loaded colony file with seed  0 and 50 individuals.\n",
      "Generating MULTI-animal dataset!\n",
      "\n",
      "A total of 50 unique classes have been found.\n",
      "The classes and respective class IDs are:\n",
      " {'Pogonomyrmex-desertorum': 0, 'Pogonomyrmex-desertorum1': 1, 'Pogonomyrmex-desertorum10': 2, 'Pogonomyrmex-desertorum11': 3, 'Pogonomyrmex-desertorum12': 4, 'Pogonomyrmex-desertorum13': 5, 'Pogonomyrmex-desertorum14': 6, 'Pogonomyrmex-desertorum15': 7, 'Pogonomyrmex-desertorum16': 8, 'Pogonomyrmex-desertorum17': 9, 'Pogonomyrmex-desertorum18': 10, 'Pogonomyrmex-desertorum19': 11, 'Pogonomyrmex-desertorum2': 12, 'Pogonomyrmex-desertorum20': 13, 'Pogonomyrmex-desertorum21': 14, 'Pogonomyrmex-desertorum22': 15, 'Pogonomyrmex-desertorum23': 16, 'Pogonomyrmex-desertorum24': 17, 'Pogonomyrmex-desertorum25': 18, 'Pogonomyrmex-desertorum26': 19, 'Pogonomyrmex-desertorum27': 20, 'Pogonomyrmex-desertorum28': 21, 'Pogonomyrmex-desertorum29': 22, 'Pogonomyrmex-desertorum3': 23, 'Pogonomyrmex-desertorum30': 24, 'Pogonomyrmex-desertorum31': 25, 'Pogonomyrmex-desertorum32': 26, 'Pogonomyrmex-desertorum33': 27, 'Pogonomyrmex-desertorum34': 28, 'Pogonomyrmex-desertorum35': 29, 'Pogonomyrmex-desertorum36': 30, 'Pogonomyrmex-desertorum37': 31, 'Pogonomyrmex-desertorum38': 32, 'Pogonomyrmex-desertorum39': 33, 'Pogonomyrmex-desertorum4': 34, 'Pogonomyrmex-desertorum40': 35, 'Pogonomyrmex-desertorum41': 36, 'Pogonomyrmex-desertorum42': 37, 'Pogonomyrmex-desertorum43': 38, 'Pogonomyrmex-desertorum44': 39, 'Pogonomyrmex-desertorum45': 40, 'Pogonomyrmex-desertorum46': 41, 'Pogonomyrmex-desertorum47': 42, 'Pogonomyrmex-desertorum48': 43, 'Pogonomyrmex-desertorum49': 44, 'Pogonomyrmex-desertorum5': 45, 'Pogonomyrmex-desertorum6': 46, 'Pogonomyrmex-desertorum7': 47, 'Pogonomyrmex-desertorum8': 48, 'Pogonomyrmex-desertorum9': 49} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define location of dataset and return all files\n",
    "#dataset_location = \"example_data/_input_multi/\"\n",
    "#target_dir = \"example_data/DLC\"\n",
    "\n",
    "dataset_location = \"C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output/\"\n",
    "target_dir = \"C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output_processed_DLC/\"\n",
    "\n",
    "all_files = [f for f in listdir(dataset_location) if isfile(join(dataset_location, f))]\n",
    "\n",
    "# next, sort files into images, depth maps, segmentation maps, data, and colony info\n",
    "dataset_img = []\n",
    "dataset_depth = []\n",
    "dataset_seg = []\n",
    "dataset_data = []\n",
    "dataset_colony = dataset_location + \"/ColonieInfo.csv\"\n",
    "\n",
    "for file in all_files:\n",
    "    loc = dataset_location + \"/\" + file\n",
    "    if file[-7:-4] == \"Img\":\n",
    "        dataset_img.append(loc)\n",
    "    elif file[-7:-4] == \"Seg\":\n",
    "        dataset_seg.append(loc)\n",
    "    elif file[-9:-4] == \"Depth\":\n",
    "        dataset_depth.append(loc)\n",
    "    elif file[-8:-4] == \"Data\":\n",
    "        dataset_data.append(loc)\n",
    "        \n",
    "print(\"Found\",len(all_files),\"files...\")\n",
    "\n",
    "# next sort the colony info into its IDs to determine the colony size and individual scales\n",
    "# one entry for each successive ID is read\n",
    "from csv import reader\n",
    "\n",
    "colony = {'seed': 0,\n",
    "            'ID': [],\n",
    "         'scale': [],\n",
    "        'weight': []}\n",
    "\n",
    "with open(dataset_colony, 'r') as colony_file:\n",
    "        print(\"reading\", file)\n",
    "        # pass the file object to reader() to get the reader object\n",
    "        csv_reader = reader(colony_file)\n",
    "        # iterate over each row in the csv using reader object\n",
    "        for r, row in enumerate(csv_reader):\n",
    "            if r == 0:\n",
    "                colony['seed'] = row[0].split(\"=\")[-1]\n",
    "            else:\n",
    "                colony['ID'].append(row[0].split(\"=\")[-1])\n",
    "                colony['weight'].append(row[1].split(\"_\")[1] + \"-\" + row[1].split(\"_\")[2])\n",
    "                colony['scale'].append(float(row[2].split(\"=\")[-1]))\n",
    "\n",
    "print(\"Loaded colony file with seed\",colony['seed'],\"and\",len(colony['ID']),\"individuals.\")\n",
    "\n",
    "# get provided classes to create a dictionary of class IDs and class names\n",
    "subject_class_names = np.unique(np.array(colony[\"weight\"]))\n",
    "subject_classes = {}\n",
    "for id,sbj in enumerate(subject_class_names):\n",
    "    subject_classes[str(sbj)] = id\n",
    "    \n",
    "if len(colony['ID']) == 1:\n",
    "    multi_animal = False\n",
    "    print(\"Generating SINGLE-animal dataset!\")\n",
    "else:\n",
    "    multi_animal = True\n",
    "    print(\"Generating MULTI-animal dataset!\")\n",
    "\n",
    "print(\"\\nA total of\",len(subject_class_names),\"unique classes have been found.\")\n",
    "print(\"The classes and respective class IDs are:\\n\",subject_classes,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the cleaned colony info, we can start loading the data associated with each frame.\n",
    "For simplicity we will simply make this a list of lists as the number of individuals.\n",
    "\n",
    "We will therefore access \"data\" as [frame] [individual] [attribute], where attributes will include [ID,bbox_x_0,bbox_y_0,...]\n",
    "\n",
    "To train a multi-animal DeepLabCut network, we mostly care about joint positions and less about bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output/10_Data.csv\n",
      "reading C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output/11_Data.csv\n",
      "reading C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output/12_Data.csv\n",
      "reading C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output/13_Data.csv\n",
      "reading C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output/14_Data.csv\n",
      "reading C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output/15_Data.csv\n",
      "reading C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output/1_Data.csv\n",
      "reading C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output/2_Data.csv\n",
      "reading C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output/3_Data.csv\n",
      "reading C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output/4_Data.csv\n",
      "reading C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output/5_Data.csv\n",
      "reading C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output/6_Data.csv\n",
      "reading C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output/7_Data.csv\n",
      "reading C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output/8_Data.csv\n",
      "reading C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output/9_Data.csv\n",
      "\n",
      "The dataset has a total of 15 generated frames.\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for file in dataset_data:\n",
    "    # store all returned coordinates for each individual\n",
    "    coords = []\n",
    "        \n",
    "    # open file in read mode\n",
    "    with open(file, 'r') as read_obj:\n",
    "        print(\"reading\", file)\n",
    "        # pass the file object to reader() to get the reader object\n",
    "        csv_reader = reader(read_obj)\n",
    "        # iterate over each row in the csv using reader object\n",
    "        for row in csv_reader:\n",
    "            # exclude camera projection row\n",
    "            if not row[0].split(\".\")[0] == \"camera_projection:\":\n",
    "                individual = [float(row[0].split(\".\")[0])]\n",
    "                # row variable is a list that represents a row in csv\n",
    "                for elem in row:\n",
    "                    try:\n",
    "                        # exclude 3D keypoint data\n",
    "                        if elem.split(\"=\")[0][-5:] != \"world\":\n",
    "                            individual.append(float(elem.split(\"=\")[-1]))\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "                coords.append(individual)\n",
    "        \n",
    "    data.append(coords)\n",
    "    \n",
    "print(\"\\nThe dataset has a total of\", len(data),\"generated frames.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there may be animals for which we don't use all bones we can return a list of all labels and exclude the respective locations from the pose data. As all animals use the same convention, we can simply read in one example and remove the corresponding indices from all animals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output/10_Data.csv\n",
      "\n",
      "Corresponding to the following indices: [60, 61, 62, 63, 64, 65, 66, 67, 110, 111, 112, 113, 114, 115, 116, 117]\n",
      "\n",
      "All labels:\n",
      "['0.BoundingBox.BoundMin.X', 'BoundingBox.BoundMin.Y', 'BoundingBox.BoundMax.X', 'BoundingBox.BoundMax.Y', 'b_t.X', 'b_t.Y', 'b_a_1.X', 'b_a_1.Y', 'b_a_2.X', 'b_a_2.Y', 'b_a_3.X', 'b_a_3.Y', 'b_a_4.X', 'b_a_4.Y', 'b_a_5.X', 'b_a_5.Y', 'b_a_5_end.X', 'b_a_5_end.Y', 'l_1_co_r.X', 'l_1_co_r.Y', 'l_1_tr_r.X', 'l_1_tr_r.Y', 'l_1_fe_r.X', 'l_1_fe_r.Y', 'l_1_ti_r.X', 'l_1_ti_r.Y', 'l_1_ta_r.X', 'l_1_ta_r.Y', 'l_1_pt_r.X', 'l_1_pt_r.Y', 'l_1_pt_r_end.X', 'l_1_pt_r_end.Y', 'l_2_co_r.X', 'l_2_co_r.Y', 'l_2_tr_r.X', 'l_2_tr_r.Y', 'l_2_fe_r.X', 'l_2_fe_r.Y', 'l_2_ti_r.X', 'l_2_ti_r.Y', 'l_2_ta_r.X', 'l_2_ta_r.Y', 'l_2_pt_r.X', 'l_2_pt_r.Y', 'l_2_pt_r_end.X', 'l_2_pt_r_end.Y', 'l_3_co_r.X', 'l_3_co_r.Y', 'l_3_tr_r.X', 'l_3_tr_r.Y', 'l_3_fe_r.X', 'l_3_fe_r.Y', 'l_3_ti_r.X', 'l_3_ti_r.Y', 'l_3_ta_r.X', 'l_3_ta_r.Y', 'l_3_pt_r.X', 'l_3_pt_r.Y', 'l_3_pt_r_end.X', 'l_3_pt_r_end.Y', 'w_1_r.X', 'w_1_r.Y', 'w_1_r_end.X', 'w_1_r_end.Y', 'w_2_r.X', 'w_2_r.Y', 'w_2_r_end.X', 'w_2_r_end.Y', 'l_1_co_l.X', 'l_1_co_l.Y', 'l_1_tr_l.X', 'l_1_tr_l.Y', 'l_1_fe_l.X', 'l_1_fe_l.Y', 'l_1_ti_l.X', 'l_1_ti_l.Y', 'l_1_ta_l.X', 'l_1_ta_l.Y', 'l_1_pt_l.X', 'l_1_pt_l.Y', 'l_1_pt_l_end.X', 'l_1_pt_l_end.Y', 'l_2_co_l.X', 'l_2_co_l.Y', 'l_2_tr_l.X', 'l_2_tr_l.Y', 'l_2_fe_l.X', 'l_2_fe_l.Y', 'l_2_ti_l.X', 'l_2_ti_l.Y', 'l_2_ta_l.X', 'l_2_ta_l.Y', 'l_2_pt_l.X', 'l_2_pt_l.Y', 'l_2_pt_l_end.X', 'l_2_pt_l_end.Y', 'l_3_co_l.X', 'l_3_co_l.Y', 'l_3_tr_l.X', 'l_3_tr_l.Y', 'l_3_fe_l.X', 'l_3_fe_l.Y', 'l_3_ti_l.X', 'l_3_ti_l.Y', 'l_3_ta_l.X', 'l_3_ta_l.Y', 'l_3_pt_l.X', 'l_3_pt_l.Y', 'l_3_pt_l_end.X', 'l_3_pt_l_end.Y', 'w_1_l.X', 'w_1_l.Y', 'w_1_l_end.X', 'w_1_l_end.Y', 'w_2_l.X', 'w_2_l.Y', 'w_2_l_end.X', 'w_2_l_end.Y', 'b_h.X', 'b_h.Y', 'ma_r.X', 'ma_r.Y', 'ma_r_end.X', 'ma_r_end.Y', 'an_1_r.X', 'an_1_r.Y', 'an_2_r.X', 'an_2_r.Y', 'an_3_r.X', 'an_3_r.Y', 'an_3_r_end.X', 'an_3_r_end.Y', 'ma_l.X', 'ma_l.Y', 'ma_l_end.X', 'ma_l_end.Y', 'an_1_l.X', 'an_1_l.Y', 'an_2_l.X', 'an_2_l.Y', 'an_3_l.X', 'an_3_l.Y', 'an_3_l_end.X', 'an_3_l_end.Y']\n"
     ]
    }
   ],
   "source": [
    "# first open and read the first line from the first imported data file\n",
    "labels = []\n",
    "entries_found = False\n",
    "entry = 0\n",
    "\n",
    "while not entries_found:\n",
    "    with open(dataset_data[entry], 'r') as read_obj:\n",
    "        print(\"reading\", read_obj.name)\n",
    "        # pass the file object to reader() to get the reader object\n",
    "        csv_reader = reader(read_obj)\n",
    "        row_0 = next(csv_reader)  # gets the first line\n",
    "        # iterate over each row in the csv using reader object\n",
    "        if row_0[0][:3] != \"cam\":\n",
    "            entries_found = True\n",
    "            for elem in row_0:\n",
    "                try:\n",
    "                    if elem.split(\"=\")[0][-5:] != \"world\":\n",
    "                        labels.append((elem.split(\"=\")[0].split(\"Bone.\")[-1]))\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        else:\n",
    "            print(\"No entries found! Reading next file... \\n\")\n",
    "            entry += 1\n",
    "\n",
    "# now let's define which labels NOT to use (in our case, all labels relating to wings)\n",
    "# ... so that just means \"omit all lables that start with 'w'\"\n",
    "\n",
    "omit_labels = [] # labels to exclude\n",
    "matched_labels = [] # excluded label IDs\n",
    "for l, label in enumerate(labels):\n",
    "    if label[0] == \"w\":\n",
    "        matched_labels.append(l)\n",
    "        omit_labels.append(label)\n",
    "        \n",
    "print(\"\\nCorresponding to the following indices:\",matched_labels)\n",
    "\n",
    "# show all used labels:\n",
    "print(\"\\nAll labels:\")\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded data and colony info we can start plotting bounding boxes on top of their respective images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform between sRGB and linear colour space (optional)\n",
    "\n",
    "def to_linear(srgb):\n",
    "    linear = np.float32(srgb) / 255.0\n",
    "    less = linear <= 0.04045\n",
    "    linear[less] = linear[less] / 12.92\n",
    "    linear[~less] = np.power((linear[~less] + 0.055) / 1.055, 2.4)\n",
    "    return linear * 255.0\n",
    "\n",
    "    \n",
    "def from_linear(linear):\n",
    "    srgb = linear.copy()\n",
    "    less = linear <= 0.0031308\n",
    "    srgb[less] = linear[less] * 12.92\n",
    "    srgb[~less] = 1.055 * np.power(linear[~less], 1.0 / 2.4) - 0.055\n",
    "    return srgb * 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loaded samples: 15\n",
      "Colony size: 50\n",
      "body parts: 62  (including X & Y coordinates)\n",
      "\n",
      "Resulting in an array of shape: (15, 6200)\n"
     ]
    }
   ],
   "source": [
    "# let's create a big dictionary to store all our dataset info and\n",
    "# save it all to the desired .csv and .h5 files for DeepLabCut to read.\n",
    "\n",
    "all_points = np.zeros((len(data), (len(colony['ID'])*(len(labels) - len(matched_labels) -4))))\n",
    "#\t- scorer   #(just one, the only scorer is the generator)\n",
    "#\t- - individuals\n",
    "#\t- - - bodyparts\n",
    "#\t- - - - coords\n",
    "\n",
    "print(\"Number of loaded samples:\",len(data))\n",
    "print(\"Colony size:\",len(colony['ID']))\n",
    "print(\"body parts:\",int(((len(labels)-4) - len(matched_labels))/2),\" (including X & Y coordinates)\\n\")\n",
    "print(\"Resulting in an array of shape:\",all_points.shape)\n",
    "\n",
    "output_file_names = [\"\" for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 12 threads for export...\n",
      "Starting Thread_0\n",
      "Starting Thread_1\n",
      "Starting Thread_2\n",
      "Starting Thread_3\n",
      "Starting Thread_4Starting Thread_5\n",
      "\n",
      "Starting Thread_6\n",
      "Starting Thread_7\n",
      "Starting Thread_8\n",
      "Starting Thread_9\n",
      "Starting Thread_10\n",
      "Starting Thread_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread_4:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Legos\\anaconda3\\envs\\tf-gpu\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"<ipython-input-7-80e3e17f87d3>\", line 45, in run\n",
      "    process_detections(self.name, self.q)\n",
      "  File \"<ipython-input-7-80e3e17f87d3>\", line 129, in process_detections\n",
      "    if seg_bin_dilated[int(individual[6 + point*2]),int(individual[5 + point*2])] != 255:\n",
      "IndexError: index 1020 is out of bounds for axis 0 with size 688\n",
      "\n",
      "Exception in thread Thread_11:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Legos\\anaconda3\\envs\\tf-gpu\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"<ipython-input-7-80e3e17f87d3>\", line 45, in run\n",
      "    process_detections(self.name, self.q)\n",
      "  File \"<ipython-input-7-80e3e17f87d3>\", line 129, in process_detections\n",
      "    if seg_bin_dilated[int(individual[6 + point*2]),int(individual[5 + point*2])] != 255:\n",
      "IndexError: index 1012 is out of bounds for axis 0 with size 988\n",
      "\n",
      "Exception in thread Thread_2:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Legos\\anaconda3\\envs\\tf-gpu\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"<ipython-input-7-80e3e17f87d3>\", line 45, in run\n",
      "    process_detections(self.name, self.q)\n",
      "  File \"<ipython-input-7-80e3e17f87d3>\", line 129, in process_detections\n",
      "    if seg_bin_dilated[int(individual[6 + point*2]),int(individual[5 + point*2])] != 255:\n",
      "IndexError: index 1023 is out of bounds for axis 0 with size 988\n",
      "\n",
      "Exception in thread Thread_3:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Legos\\anaconda3\\envs\\tf-gpu\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"<ipython-input-7-80e3e17f87d3>\", line 45, in run\n",
      "    process_detections(self.name, self.q)\n",
      "  File \"<ipython-input-7-80e3e17f87d3>\", line 129, in process_detections\n",
      "    if seg_bin_dilated[int(individual[6 + point*2]),int(individual[5 + point*2])] != 255:\n",
      "IndexError: index 1009 is out of bounds for axis 0 with size 988\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting Thread_0\n",
      "Exiting Thread_5\n",
      "Exiting Thread_9\n",
      "Exiting Thread_10\n",
      "Exiting Thread_1\n",
      "Exiting Thread_8\n",
      "Exiting Thread_7\n",
      "Exiting Main export Thread\n",
      "Total time elapsed: 2.1094608306884766 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread_6:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Legos\\anaconda3\\envs\\tf-gpu\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"<ipython-input-7-80e3e17f87d3>\", line 45, in run\n",
      "    process_detections(self.name, self.q)\n",
      "  File \"<ipython-input-7-80e3e17f87d3>\", line 80, in process_detections\n",
      "    seg_img = cv2.imread(dataset_seg[i])\n",
      "IndexError: list index out of range\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create unique colours for each ID\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# alright. Let's take it from the top and fucking multi-thread this.\n",
    "import threading\n",
    "import queue\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def fix_bounding_boxes(coords,max_val = [1024,1024]):\n",
    "    # fix bounding box coordinates so they do not reach beyond the image\n",
    "    fixed_coords = []\n",
    "    for c, coord in enumerate(coords):\n",
    "        if c == 0 or c == 2:\n",
    "            max_val_temp = max_val[0]\n",
    "        else:\n",
    "            max_val_temp = max_val[1]\n",
    "            \n",
    "        if coord >= max_val_temp:\n",
    "            coord = max_val_temp\n",
    "        elif coord <= 0:\n",
    "            coord = 0\n",
    "        \n",
    "        fixed_coords.append(int(coord))\n",
    "        \n",
    "    return fixed_coords\n",
    "\n",
    "def getThreads():\n",
    "    \"\"\" Returns the number of available threads on a posix/win based system \"\"\"\n",
    "    if sys.platform == 'win32':\n",
    "        return int(os.environ['NUMBER_OF_PROCESSORS'])\n",
    "    else:\n",
    "        return int(os.popen('grep -c cores /proc/cpuinfo').read())\n",
    "\n",
    "class exportThread(threading.Thread):\n",
    "    def __init__(self, threadID, name, q):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.threadID = threadID\n",
    "        self.name = name\n",
    "        self.q = q\n",
    "\n",
    "    def run(self):\n",
    "        print(\"Starting \" + self.name)\n",
    "        process_detections(self.name, self.q)\n",
    "        print(\"Exiting \" + self.name)\n",
    "        \n",
    "def createThreadList(num_threads):\n",
    "    threadNames = []\n",
    "    for t in range(num_threads):\n",
    "        threadNames.append(\"Thread_\" + str(t))\n",
    "\n",
    "    return threadNames\n",
    "\n",
    "def process_detections(threadName, q):\n",
    "    while not exitFlag_export:\n",
    "        queueLock.acquire()\n",
    "        if not workQueue_export.empty():\n",
    "            \n",
    "            data_input = q.get()\n",
    "            i = data_input[0]\n",
    "            img = data_input[1]\n",
    "            queueLock.release()\n",
    "            \n",
    "            display_img = cv2.imread(img)\n",
    "            display_img_orig = display_img.copy()\n",
    "            \n",
    "            img_shape = display_img.shape\n",
    "            \n",
    "            # only add images that contain visibile individuals\n",
    "            is_empty = True\n",
    "            \n",
    "            img_name = target_dir + \"/\" + img.split('/')[-1][:-4] + \"_synth\" + \".png\"\n",
    "            # write the file path to the all_points array\n",
    "            output_file_names[i] = img_name\n",
    "\n",
    "            img_info = []\n",
    "                \n",
    "            # compute visibility for each individual\n",
    "            seg_img = cv2.imread(dataset_seg[i])\n",
    "            seg_img_display = seg_img.copy()\n",
    "            \n",
    "            for im, individual in enumerate(data[i]):\n",
    "                fontColor = (int(ID_colours[int(individual[0]),0]),\n",
    "                             int(ID_colours[int(individual[0]),1]),\n",
    "                             int(ID_colours[int(individual[0]),2]))\n",
    "                bbox = fix_bounding_boxes(individual[1:5],max_val=display_img.shape)\n",
    "                    \n",
    "                # FOR SOME REASON OCCASIONALLY THE ID OF THE SEG FILE IS LOWER THAN THE DATA FILE\n",
    "                # with: ID = red_channel/255 * im\n",
    "                # red_channel = (ID/im) * 255\n",
    "                ID_red_val = int((individual[0]/len(colony['ID']))*255)\n",
    "                \n",
    "                try:\n",
    "                    ID_mask = cv2.inRange(seg_img[bbox[1]:bbox[3],bbox[0]:bbox[2]], np.array([0,0, ID_red_val - 2]), np.array([0,0, ID_red_val + 2]))\n",
    "                    indivual_occupancy = cv2.countNonZero(ID_mask)\n",
    "                except:\n",
    "                    indivual_occupancy = 1\n",
    "\n",
    "                #indivual_occupancy = np.count_nonzero((seg_img == [0, 0, int((individual[0]/len(colony['ID']))*255)]).all(axis = 2)) + np.count_nonzero((seg_img == [0, 0, int((individual[0]/len(colony['ID']))*255 - 1)]).all(axis = 2)) + np.count_nonzero((seg_img == [0, 0, int((individual[0]/len(colony['ID']))*255 + 1)]).all(axis = 2))\n",
    "                bbox_area = abs((bbox[2] - bbox[0]) * (bbox[3] - bbox[1])) + 1\n",
    "                bbox_occupancy = indivual_occupancy / bbox_area\n",
    "                #print(\"Individual\", individual[0], \"with bounding box occupancy \",bbox_occupancy)\n",
    "                \n",
    "                #cv2.putText(display_img, \"ID: \" + str(int(individual[0])), (bbox[0] + 10,bbox[3] - 10), font, fontScale, fontColor, lineType)\n",
    "                if bbox_occupancy > visibility_threshold:\n",
    "                    # let's binarise the image and dilate it to make sure all points that visible are found\n",
    "                    seg_bin = cv2.inRange(seg_img, np.array([0,0, ID_red_val - 2]), np.array([0,245, ID_red_val + 2]))\n",
    "                    kernel = np.ones((5,5),np.uint8)\n",
    "                    seg_bin_dilated = cv2.dilate(seg_bin,kernel,iterations = 1)\n",
    "                    \n",
    "                    output_cell = 0    \n",
    "                    for point in range(int(len(individual[5:])/2)):\n",
    "                        # get rid of all invalid points first. Those should simply stay NaN in the array\n",
    "                        if point*2 + 4 in matched_labels:\n",
    "                            pass\n",
    "                        elif individual[point*2 + 5] > img_shape[0] or individual[point*2 + 5] < 0 or individual[point*2 + 6] > img_shape[1] or individual[point*2 + 6] < 0:\n",
    "                            output_cell += 1\n",
    "                        else:\n",
    "                            # now throw the coordinates to the correct location\n",
    "                            out_row = i\n",
    "                            out_column = int(individual[0]) * (int(len(labels) - len(matched_labels) - 4)) + output_cell * 2\n",
    "                            # exclude negative keypoints\n",
    "                            if individual[point*2 + 5] < 0.1 or individual[point*2 + 6] < 0.1:\n",
    "                                individual[point*2 + 5] = 0 # X\n",
    "                                individual[point*2 + 6] = 0 # Y\n",
    "                            # exlucde occluded keypoints by checking their visibility in the segmentation map   \n",
    "                            if EXCLUDE_OCCLUDED_KEYPOINTS:\n",
    "                                if seg_bin_dilated[int(individual[6 + point*2]),int(individual[5 + point*2])] != 255:                   \n",
    "                                    individual[point*2 + 5] = 0 # X\n",
    "                                    individual[point*2 + 6] = 0 # Y\n",
    "                            all_points[out_row][out_column] = round(individual[point*2 + 5],1) # X\n",
    "                            all_points[out_row][out_column + 1] = round(individual[point*2 + 6],1) # Y\n",
    "                        \n",
    "                            output_cell += 1\n",
    "                   \n",
    "            cv2.imwrite(img_name, display_img)\n",
    "            \n",
    "        else:\n",
    "            queueLock.release()\n",
    "            \n",
    "# setup as many threads as there are (virtual) CPU cores\n",
    "exitFlag_export = 0\n",
    "# only use a fourth of the number of CPUs for export as hugin and enfuse utilise multi core processing in part\n",
    "threadList_export = createThreadList(getThreads())\n",
    "print(\"Using\", len(threadList_export), \"threads for export...\")\n",
    "queueLock = threading.Lock()\n",
    "\n",
    "# define paths to all images and set the maximum number of items in the queue equivalent to the number of images\n",
    "workQueue_export = queue.Queue(len(dataset_img))\n",
    "threads = []\n",
    "threadID = 1\n",
    "\n",
    "np.random.seed(seed=1)\n",
    "ID_colours = np.random.randint(255, size=(len(colony['ID']), 3))\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 0.5\n",
    "lineType = 2\n",
    "\n",
    "# we can optionally remove occluded points from the dataframe\n",
    "EXCLUDE_OCCLUDED_KEYPOINTS = True\n",
    "\n",
    "# we can additionally plot the points in the data files to check joint locations\n",
    "plot_joints = True\n",
    "\n",
    "# remember to refine an export folder when saving out your dataset\n",
    "generate_dataset = True\n",
    "\n",
    "# determine the proportion of a bounding box that needs to be filled before considering the visibility as too low\n",
    "# WARNING: At the moment the ID shown in segmentation maps does not always correspond to the ID in the data file (off by 1)\n",
    "visibility_threshold = 0.01\n",
    "\n",
    "timer = time.time()\n",
    "\n",
    "# Create new threads\n",
    "for tName in threadList_export:\n",
    "    thread = exportThread(threadID, tName, workQueue_export)\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "    threadID += 1\n",
    "\n",
    "# Fill the queue with stacks\n",
    "queueLock.acquire()\n",
    "for i,img in enumerate(dataset_img):\n",
    "    workQueue_export.put([i, img])\n",
    "queueLock.release()\n",
    "\n",
    "# Wait for queue to empty\n",
    "while not workQueue_export.empty():\n",
    "    pass\n",
    "\n",
    "# Notify threads it's time to exit\n",
    "exitFlag_export = 1\n",
    "\n",
    "# Wait for all threads to complete\n",
    "for t in threads:\n",
    "    t.join()\n",
    "print(\"Exiting Main export Thread\")\n",
    "\n",
    "# close all windows if they were opened\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Total time elapsed:\",time.time()-timer,\"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, dump it all into one **DLC-conform pandas (.h5)** file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low let's create the required hierarchy\n",
    "scorer = [\"FARTS\" for i in range(len(all_points[0]))]\n",
    "individuals = []\n",
    "\n",
    "for ind in range(len(colony['ID'])):\n",
    "    individual = [\"id_\" + str(colony[\"weight\"][ind]+\"_num_\"+str(ind)) for i in range(int((len(labels)-4) - len(matched_labels)))]\n",
    "    individuals.extend(individual)\n",
    "    \n",
    "bodyparts_filtered = [item.split(\".\")[0] for item in labels if item not in omit_labels][4:]\n",
    "bodyparts = []\n",
    "\n",
    "for i in range(len(colony['ID'])):\n",
    "    bodyparts.extend(bodyparts_filtered)\n",
    "    \n",
    "coords = []\n",
    "for i in range(int(len(all_points[0])/2)):\n",
    "    coords.extend([\"x\",\"y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all elemts for the **Multi-Index** hierachy are defined, we can combine them into the **final dataframe**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multi_animal:\n",
    "    categories = [scorer, individuals, bodyparts, coords]\n",
    "    categories_tuples = list(zip(*categories))\n",
    "    columns = pd.MultiIndex.from_tuples(categories_tuples, names=[\"scorer\",\n",
    "                                                               \"individuals\",\n",
    "                                                               \"bodyparts\",\n",
    "                                                               \"coords\"])\n",
    "else:\n",
    "    categories = [scorer, bodyparts, coords]\n",
    "    categories_tuples = list(zip(*categories))\n",
    "    columns = pd.MultiIndex.from_tuples(categories_tuples, names=[\"scorer\",\n",
    "                                                               \"bodyparts\",\n",
    "                                                               \"coords\"])\n",
    "final_dataframe = pd.DataFrame(all_points, index = output_file_names, columns=columns)\n",
    "# convert all zeros to NaN\n",
    "final_dataframe = final_dataframe.replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>scorer</th>\n",
       "      <th colspan=\"21\" halign=\"left\">FARTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>individuals</th>\n",
       "      <th colspan=\"10\" halign=\"left\">id_Pogonomyrmex-desertorum_num_0</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">id_Pogonomyrmex-desertorum49_num_49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodyparts</th>\n",
       "      <th colspan=\"2\" halign=\"left\">b_t</th>\n",
       "      <th colspan=\"2\" halign=\"left\">b_a_1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">b_a_2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">b_a_3</th>\n",
       "      <th colspan=\"2\" halign=\"left\">b_a_4</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ma_l_end</th>\n",
       "      <th colspan=\"2\" halign=\"left\">an_1_l</th>\n",
       "      <th colspan=\"2\" halign=\"left\">an_2_l</th>\n",
       "      <th colspan=\"2\" halign=\"left\">an_3_l</th>\n",
       "      <th colspan=\"2\" halign=\"left\">an_3_l_end</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coords</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>...</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output_processed/10_Img_synth.png</th>\n",
       "      <td>721.8</td>\n",
       "      <td>448.4</td>\n",
       "      <td>695.9</td>\n",
       "      <td>472.8</td>\n",
       "      <td>693.4</td>\n",
       "      <td>481.4</td>\n",
       "      <td>686.5</td>\n",
       "      <td>486.8</td>\n",
       "      <td>678.7</td>\n",
       "      <td>491.8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output_processed/11_Img_synth.png</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500.6</td>\n",
       "      <td>622.2</td>\n",
       "      <td>498.7</td>\n",
       "      <td>624.3</td>\n",
       "      <td>498.6</td>\n",
       "      <td>620.4</td>\n",
       "      <td>502.4</td>\n",
       "      <td>619.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output_processed/12_Img_synth.png</th>\n",
       "      <td>982.5</td>\n",
       "      <td>346.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output_processed/13_Img_synth.png</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output_processed/14_Img_synth.png</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>522.9</td>\n",
       "      <td>382.6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output_processed/15_Img_synth.png</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output_processed/1_Img_synth.png</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output_processed/2_Img_synth.png</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output_processed/3_Img_synth.png</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output_processed/4_Img_synth.png</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output_processed/5_Img_synth.png</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output_processed/6_Img_synth.png</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output_processed/7_Img_synth.png</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output_processed/8_Img_synth.png</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS_STICKS/Output_processed/9_Img_synth.png</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 6200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "scorer                                                                        FARTS  \\\n",
       "individuals                                        id_Pogonomyrmex-desertorum_num_0   \n",
       "bodyparts                                                                       b_t   \n",
       "coords                                                                            x   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                            721.8   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                              NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                            982.5   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                              NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                              NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                              NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                              NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                              NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                              NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                              NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                              NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                              NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                              NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                              NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                              NaN   \n",
       "\n",
       "scorer                                                                   \\\n",
       "individuals                                                               \n",
       "bodyparts                                                  b_a_1          \n",
       "coords                                                  y      x      y   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...  448.4  695.9  472.8   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...  346.5    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "\n",
       "scorer                                                                   \\\n",
       "individuals                                                               \n",
       "bodyparts                                           b_a_2         b_a_3   \n",
       "coords                                                  x      y      x   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...  693.4  481.4  686.5   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "\n",
       "scorer                                                                   ...  \\\n",
       "individuals                                                              ...   \n",
       "bodyparts                                                  b_a_4         ...   \n",
       "coords                                                  y      x      y  ...   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...  486.8  678.7  491.8  ...   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN  ...   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN  ...   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN  ...   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN  522.9  382.6  ...   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN  ...   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN  ...   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN  ...   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN  ...   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN  ...   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN  ...   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN  ...   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN  ...   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN  ...   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN  ...   \n",
       "\n",
       "scorer                                                                                  \\\n",
       "individuals                                        id_Pogonomyrmex-desertorum49_num_49   \n",
       "bodyparts                                                                     ma_l_end   \n",
       "coords                                                                               x   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                                 NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                                 NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                                 NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                                 NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                                 NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                                 NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                                 NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                                 NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                                 NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                                 NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                                 NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                                 NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                                 NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                                 NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...                                 NaN   \n",
       "\n",
       "scorer                                                                       \\\n",
       "individuals                                                                   \n",
       "bodyparts                                              an_1_l        an_2_l   \n",
       "coords                                               y      x      y      x   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS... NaN    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS... NaN  500.6  622.2  498.7   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS... NaN    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS... NaN    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS... NaN    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS... NaN    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS... NaN    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS... NaN    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS... NaN    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS... NaN    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS... NaN    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS... NaN    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS... NaN    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS... NaN    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS... NaN    NaN    NaN    NaN   \n",
       "\n",
       "scorer                                                                   \\\n",
       "individuals                                                               \n",
       "bodyparts                                                 an_3_l          \n",
       "coords                                                  y      x      y   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...  624.3  498.6  620.4   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...    NaN    NaN    NaN   \n",
       "\n",
       "scorer                                                                \n",
       "individuals                                                           \n",
       "bodyparts                                          an_3_l_end         \n",
       "coords                                                      x      y  \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...        NaN    NaN  \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...      502.4  619.9  \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...        NaN    NaN  \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...        NaN    NaN  \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...        NaN    NaN  \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...        NaN    NaN  \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...        NaN    NaN  \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...        NaN    NaN  \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...        NaN    NaN  \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...        NaN    NaN  \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...        NaN    NaN  \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...        NaN    NaN  \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...        NaN    NaN  \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...        NaN    NaN  \n",
       "C:/Users/Legos/Documents/PhD/FARTS/UNREAL/FARTS...        NaN    NaN  \n",
       "\n",
       "[15 rows x 6200 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "HDF5ExtError",
     "evalue": "HDF5 error back trace\n\n  File \"C:\\ci\\hdf5_1545244154871\\work\\src\\H5A.c\", line 279, in H5Acreate2\n    unable to create attribute\n  File \"C:\\ci\\hdf5_1545244154871\\work\\src\\H5Aint.c\", line 323, in H5A__create\n    unable to create attribute\n  File \"C:\\ci\\hdf5_1545244154871\\work\\src\\H5Aint.c\", line 277, in H5A__create_common\n    unable to create attribute in object header\n  File \"C:\\ci\\hdf5_1545244154871\\work\\src\\H5Oattribute.c\", line 335, in H5O__attr_create\n    unable to create new attribute in header\n  File \"C:\\ci\\hdf5_1545244154871\\work\\src\\H5Omessage.c\", line 222, in H5O__msg_append_real\n    unable to create new message\n  File \"C:\\ci\\hdf5_1545244154871\\work\\src\\H5Omessage.c\", line 1926, in H5O__msg_alloc\n    unable to allocate space for message\n  File \"C:\\ci\\hdf5_1545244154871\\work\\src\\H5Oalloc.c\", line 1312, in H5O__alloc\n    object header message is too large\n\nEnd of HDF5 error back trace\n\nCan't set attribute 'non_index_axes' in node:\n /df_with_missing (Group) ''.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHDF5ExtError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-1aeed565d07f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;34m\"df_with_missing\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"table\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     mode=\"w\")\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_hdf\u001b[1;34m(self, path_or_buf, key, mode, complevel, complib, append, format, index, min_itemsize, nan_rep, dropna, data_columns, errors, encoding)\u001b[0m\n\u001b[0;32m   2444\u001b[0m             \u001b[0mdata_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_columns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2445\u001b[0m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2446\u001b[1;33m             \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2447\u001b[0m         )\n\u001b[0;32m   2448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mto_hdf\u001b[1;34m(path_or_buf, key, value, mode, complevel, complib, append, format, index, min_itemsize, nan_rep, dropna, data_columns, errors, encoding)\u001b[0m\n\u001b[0;32m    268\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomplevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomplevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomplib\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomplib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         ) as store:\n\u001b[1;32m--> 270\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(store)\u001b[0m\n\u001b[0;32m    260\u001b[0m             \u001b[0mdata_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_columns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m         )\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mput\u001b[1;34m(self, key, value, format, index, append, complib, complevel, min_itemsize, nan_rep, data_columns, encoding, errors, track_times)\u001b[0m\n\u001b[0;32m   1127\u001b[0m             \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m             \u001b[0mtrack_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_times\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m         )\n\u001b[0;32m   1131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36m_write_to_group\u001b[1;34m(self, key, value, format, axes, index, append, complib, complevel, fletcher32, min_itemsize, chunksize, expectedrows, dropna, nan_rep, data_columns, encoding, errors, track_times)\u001b[0m\n\u001b[0;32m   1799\u001b[0m             \u001b[0mnan_rep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnan_rep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1800\u001b[0m             \u001b[0mdata_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_columns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1801\u001b[1;33m             \u001b[0mtrack_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_times\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1802\u001b[0m         )\n\u001b[0;32m   1803\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, obj, axes, append, complib, complevel, fletcher32, min_itemsize, chunksize, expectedrows, dropna, nan_rep, data_columns, track_times)\u001b[0m\n\u001b[0;32m   4253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4254\u001b[0m             \u001b[1;31m# set the table attributes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4255\u001b[1;33m             \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_attrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4257\u001b[0m             \u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"track_times\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrack_times\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mset_attrs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3447\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_cols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3448\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues_cols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3449\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnon_index_axes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnon_index_axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3450\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3451\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan_rep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan_rep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tables\\attributeset.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[1;31m# Set the attribute.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 483\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_g__setattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m         \u001b[1;31m# Log new attribute addition.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tables\\attributeset.py\u001b[0m in \u001b[0;36m_g__setattr\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_g_setattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_v_node\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[1;31m# New attribute or value. Introduce it into the local\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mtables/hdf5extension.pyx\u001b[0m in \u001b[0;36mtables.hdf5extension.AttributeSet._g_setattr\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mHDF5ExtError\u001b[0m: HDF5 error back trace\n\n  File \"C:\\ci\\hdf5_1545244154871\\work\\src\\H5A.c\", line 279, in H5Acreate2\n    unable to create attribute\n  File \"C:\\ci\\hdf5_1545244154871\\work\\src\\H5Aint.c\", line 323, in H5A__create\n    unable to create attribute\n  File \"C:\\ci\\hdf5_1545244154871\\work\\src\\H5Aint.c\", line 277, in H5A__create_common\n    unable to create attribute in object header\n  File \"C:\\ci\\hdf5_1545244154871\\work\\src\\H5Oattribute.c\", line 335, in H5O__attr_create\n    unable to create new attribute in header\n  File \"C:\\ci\\hdf5_1545244154871\\work\\src\\H5Omessage.c\", line 222, in H5O__msg_append_real\n    unable to create new message\n  File \"C:\\ci\\hdf5_1545244154871\\work\\src\\H5Omessage.c\", line 1926, in H5O__msg_alloc\n    unable to allocate space for message\n  File \"C:\\ci\\hdf5_1545244154871\\work\\src\\H5Oalloc.c\", line 1312, in H5O__alloc\n    object header message is too large\n\nEnd of HDF5 error back trace\n\nCan't set attribute 'non_index_axes' in node:\n /df_with_missing (Group) ''."
     ]
    }
   ],
   "source": [
    "final_dataframe.to_csv(os.path.join(target_dir, \"CollectedData_FARTS.csv\"))\n",
    "\n",
    "# IF the function below fails, this is likely due to exceeding the number of columns supported by HDF5 files!\n",
    "# Restrict the number of simulated animals to < 20 if the goal is to train a DLC network\n",
    "\n",
    "final_dataframe.to_hdf(\n",
    "    os.path.join(target_dir, \"CollectedData_\" + \"FARTS\" + \".h5\"),\n",
    "    \"df_with_missing\",\n",
    "    format=\"table\",\n",
    "    mode=\"w\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
