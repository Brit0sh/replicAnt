{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute (YOLO) detection accuracy\n",
    "First, we'll import the ground truth video and blender tracked file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The imported clip: I:/BENCHMARK/sub_colony_tracking/pre_processed_video/rec_climate_chamber_sub_colony_base_10000_frames_CLEAN.mp4 has a total of 2000 frames.\n",
      "\n",
      "importing tracks...\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.001.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.002.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.003.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.004.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.005.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.006.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.007.csv  with 994 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.008.csv  with 1000 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.009.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.010.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.011.csv  with 877 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.012.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.013.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.014.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.015.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.016.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.017.csv  with 971 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.018.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.019.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.020.csv  with 512 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.021.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.022.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.023.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.024.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.025.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.026.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.027.csv  with 787 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.028.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.029.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.030.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.031.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.032.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.033.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.034.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.035.csv  with 748 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.036.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.037.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.038.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.039.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.040.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.041.csv  with 191 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.042.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.043.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.044.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.045.csv  with 1000 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.046.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.047.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.048.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.049.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.050.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.051.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.052.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.053.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.054.csv  with 131 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.055.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.056.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.057.csv  with 291 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.058.csv  with 219 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.059.csv  with 510 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.060.csv  with 701 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.061.csv  with 251 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.062.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.063.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.064.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.065.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.066.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.067.csv  with 1001 points.\n",
      "imported exportrec_climate_chamber_sub_colony_base_10000_frames_Track.068.csv  with 1001 points.\n",
      "\n",
      "Successfully combined the tracks of 68 individuals for training and display!\n",
      "\n",
      "Displaying tracks loaded from: I:/BENCHMARK/sub_colony_tracking/NAT/export_base_NAT/\n",
      "\n",
      "Displaying tracked footage!\n",
      "press 'q' to end display\n",
      "\n",
      "Reached last frame of specified video or ended by user input.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndef import_ground_truth(path):\\n    tracks = np.loadtxt(path, delimiter=\",\")\\n    tracks = tracks.astype(int)\\n    \\n    print(\"Imported tracks successfully from\", path)\\n    \\n    return tracks\\n\\ntracks.append(import_ground_truth(path=\"J:/tracking_validation/export_base_NAT/_all_tracks.csv\"))\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from operator import itemgetter\n",
    "\n",
    "# now for the file management fucntions\n",
    "from Antrax_base import import_tracks, display_video, get_exact_frame, extractPatches, display_patches, sortByDistance\n",
    "\n",
    "export_paths = [\"I:/BENCHMARK/sub_colony_tracking/NAT/export_base_NAT/\"] # add more paths here, if desired\n",
    "video = \"I:/BENCHMARK/sub_colony_tracking/pre_processed_video/rec_climate_chamber_sub_colony_base_10000_frames_CLEAN.mp4\"\n",
    "\n",
    "# enter the number of annotated frames:\n",
    "tracked_frames = 1000\n",
    "\n",
    "# now we can load the captured video file and display it\n",
    "cap = cv2.VideoCapture(video)\n",
    "\n",
    "# check the number of frames of the imported video file\n",
    "numFramesMax = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"The imported clip:\", video, \"has a total of\",numFramesMax ,\"frames.\\n\")\n",
    "\n",
    "# now let's load all tracks listed in the export_paths\n",
    "tracks = []\n",
    "\n",
    "try:\n",
    "    for folder in export_paths:\n",
    "        # You can export all tracks into a single .csv file by setting \"export=True\"\n",
    "        tracks.append(import_tracks(folder, numFramesMax, export=False))\n",
    "\n",
    "        # The following function is used to display the tracks you imported.\n",
    "        # You can press \"q\" while hovering over the displayed video to exit.\n",
    "        print(\"\\nDisplaying tracks loaded from:\", folder)\n",
    "        display_video(cap, tracks[-1], show=(0, tracked_frames), scale=0.3)\n",
    "except IndexError:\n",
    "    print(\"WARNING: Issue importing tracks. Ensure correct numbers of frames are given\")\n",
    "\"\"\"\n",
    "def import_ground_truth(path):\n",
    "    tracks = np.loadtxt(path, delimiter=\",\")\n",
    "    tracks = tracks.astype(int)\n",
    "    \n",
    "    print(\"Imported tracks successfully from\", path)\n",
    "    \n",
    "    return tracks\n",
    "\n",
    "tracks.append(import_ground_truth(path=\"J:/tracking_validation/export_base_NAT/_all_tracks.csv\"))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load our trained network and run inference on the loaded video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load darknet with compiled DLLs for windows from respective path\n",
    "import sys\n",
    "sys.path.append('I:\\\\Antrax\\\\darknet-master\\\\build\\darknet\\\\x64')\n",
    "# load weights trained on synthetic data only\n",
    "sys.path.append('I:\\\\FARTS\\\\trained_YOLO_networks\\\\synthetic_only_single_class')\n",
    "# load weights trained on real data only\n",
    "sys.path.append('I:\\\\FARTS\\\\trained_YOLO_networks\\\\real_only_multi_class')\n",
    "import darknet\n",
    "import imutils\n",
    "\n",
    "def nonMaximumSupression(detections):\n",
    "    \"\"\"\n",
    "    :param detections: detections returned from darknet\n",
    "    :return: only detection of highest confidence. Return None, if no individual was detected\n",
    "    \"\"\"\n",
    "    if len(detections) != 0:\n",
    "        det_sorted = sorted(detections, key=itemgetter(2))\n",
    "        max_conf_detection = det_sorted[0][0]\n",
    "    else:\n",
    "        max_conf_detection = 'No Detect'\n",
    "    return max_conf_detection\n",
    "\n",
    "# load configuration and weights (synthetic)\n",
    "yolo_cfg = 'I:/Blender/OmniTrax/OmniTrax_WIP/YOLO/atta_single_class/yolov4-big_and_small_ants_2048.cfg'\n",
    "yolo_weights = 'I:/Blender/OmniTrax/OmniTrax_WIP/YOLO/atta_single_class/yolov4-big_and_small_ants_1024px_refined_with_2048_px_27000.weights'\n",
    "yolo_data = 'I:/Blender/OmniTrax/OmniTrax_WIP/YOLO/atta_single_class/obj.data'\n",
    "yolo_names = 'I:/Blender/OmniTrax/OmniTrax_WIP/YOLO/atta_single_class/obj.names'\n",
    "\n",
    "# load configuration and weights (real)\n",
    "#yolo_cfg = 'I:/FARTS/trained_YOLO_networks/real_only_multi_class/yolov4_ant_weight_testing.cfg'\n",
    "#yolo_weights = 'I:/FARTS/trained_YOLO_networks/real_only_multi_class/yolov4_ant_weight_24000.weights'\n",
    "#yolo_data = 'I:/FARTS/trained_YOLO_networks/real_only_multi_class/data/obj.data'\n",
    "#yolo_names = 'I:/FARTS/trained_YOLO_networks/real_only_multi_class/data/obj.names'\n",
    "\n",
    "from ctypes import *\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import darknet\n",
    "\n",
    "def convertBack(x, y, w, h):\n",
    "    xmin = int(round(x - (w / 2)))\n",
    "    xmax = int(round(x + (w / 2)))\n",
    "    ymin = int(round(y - (h / 2)))\n",
    "    ymax = int(round(y + (h / 2)))\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "\n",
    "def cvDrawBoxes(detections, img, min_size=20, constant_size=False):\n",
    "    for detection in detections:\n",
    "\n",
    "        x, y, w, h = detection[2][0],\\\n",
    "            detection[2][1],\\\n",
    "            detection[2][2],\\\n",
    "            detection[2][3]\n",
    "        \n",
    "        if w >= min_size and h  >= min_size:\n",
    "            \n",
    "            if constant_size:\n",
    "                w, h = constant_size, constant_size\n",
    "\n",
    "            xmin, ymin, xmax, ymax = convertBack(\n",
    "                float(x), float(y), float(w), float(h))\n",
    "            pt1 = (xmin, ymin)\n",
    "            pt2 = (xmax, ymax)\n",
    "            cv2.rectangle(img, pt1, pt2, (150, 0, 160), 1)\n",
    "            cv2.putText(img,\n",
    "                        detection[0].decode() +\n",
    "                        \" [\" + str(round(detection[1] * 100, 2)) + \"]\",\n",
    "                        (pt1[0], pt1[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.3,\n",
    "                        [150, 0, 160], 2)\n",
    "    return img\n",
    "\n",
    "\n",
    "netMain = None\n",
    "metaMain = None\n",
    "altNames = None\n",
    "\n",
    "configPath = yolo_cfg\n",
    "weightPath = yolo_weights\n",
    "metaPath = yolo_data\n",
    "\n",
    "if not os.path.exists(configPath):\n",
    "    raise ValueError(\"Invalid config path `\" +\n",
    "                     os.path.abspath(configPath)+\"`\")\n",
    "if not os.path.exists(weightPath):\n",
    "    raise ValueError(\"Invalid weight path `\" +\n",
    "                     os.path.abspath(weightPath)+\"`\")\n",
    "if not os.path.exists(metaPath):\n",
    "    raise ValueError(\"Invalid data file path `\" +\n",
    "                     os.path.abspath(metaPath)+\"`\")\n",
    "if netMain is None:\n",
    "    netMain = darknet.load_net_custom(configPath.encode(\n",
    "        \"ascii\"), weightPath.encode(\"ascii\"), 0, 1)  # batch size = 1\n",
    "if metaMain is None:\n",
    "    metaMain = darknet.load_meta(metaPath.encode(\"ascii\"))\n",
    "if altNames is None:\n",
    "    try:\n",
    "        with open(metaPath) as metaFH:\n",
    "            metaContents = metaFH.read()\n",
    "            import re\n",
    "            match = re.search(\"names *= *(.*)$\", metaContents,\n",
    "                              re.IGNORECASE | re.MULTILINE)\n",
    "            if match:\n",
    "                result = match.group(1)\n",
    "            else:\n",
    "                result = None\n",
    "            try:\n",
    "                if os.path.exists(result):\n",
    "                    with open(result) as namesFH:\n",
    "                        namesList = namesFH.read().strip().split(\"\\n\")\n",
    "                        altNames = [x.strip() for x in namesList]\n",
    "            except TypeError:\n",
    "                pass\n",
    "    except Exception:\n",
    "        pass\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "print(\"Starting the YOLO loop...\")\n",
    "\n",
    "# Create an image we reuse for each detect\n",
    "darknet_image = darknet.make_image(darknet.network_width(netMain),\n",
    "                                darknet.network_height(netMain),3)\n",
    "\n",
    "all_detection_centres = []\n",
    "\n",
    "frame_counter = 0\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "out = cv2.VideoWriter(video[:-4].split(\"/\")[-1]+'_detections.avi', fourcc, 20.0, (darknet.network_width(netMain),darknet.network_height(netMain)))\n",
    "\n",
    "def scale_detections(x,y,network_w,network_h,output_w,output_h):\n",
    "    scaled_x = x * (output_w / network_w)\n",
    "    scaled_y = (network_h - y) * (output_h / network_h) # y is inverted\n",
    "    return [scaled_x, scaled_y]\n",
    "\n",
    "start_time = time.time()\n",
    "while True:\n",
    "    if frame_counter == tracked_frames: \n",
    "        break\n",
    "        \n",
    "    prev_time = time.time()\n",
    "    ret, frame_read = cap.read()\n",
    "    frame_rgb = cv2.cvtColor(frame_read, cv2.COLOR_BGR2RGB)\n",
    "    frame_resized = cv2.resize(frame_rgb,\n",
    "                               (darknet.network_width(netMain),\n",
    "                                darknet.network_height(netMain)),\n",
    "                               interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    darknet.copy_image_from_bytes(darknet_image,frame_resized.tobytes())\n",
    "    \n",
    "    # thresh : detection threshold -> lower = more sensitive\n",
    "    # nms : non maximum suppression -> higher = allow for closer proximity between detections\n",
    "    detections = darknet.detect_image(netMain, metaMain, darknet_image, thresh=0.4, nms=0.55)\n",
    "    print(\"Frame:\",frame_counter + 1)\n",
    "    min_size = 15 # minimum size for rerturned detecions\n",
    "    viable_detections = []\n",
    "    \n",
    "    for detection in detections:\n",
    "        if detection[2][2] >= min_size and detection[2][3] >= min_size:\n",
    "            # we need to scale the detections to the original imagesize, as they are downsampled above\n",
    "            scaled_xy = scale_detections(x=detection[2][0], y=detection[2][1],\n",
    "                                         network_w=darknet.network_width(netMain), network_h=darknet.network_height(netMain),\n",
    "                                         output_w=frame_rgb.shape[1],output_h=frame_rgb.shape[0])\n",
    "            viable_detections.append(scaled_xy)\n",
    "            \n",
    "    all_detection_centres.append(viable_detections)\n",
    "        \n",
    "    image = cvDrawBoxes(detections, frame_resized, min_size=min_size, constant_size=40)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # print(1/(time.time()-prev_time))\n",
    "    out.write(image)\n",
    "    cv2.imshow('Detections on video', image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "    frame_counter += 1\n",
    "    \n",
    "print(\"Time elapsed\",time.time()-start_time)\n",
    "print(\"FPS:\", frame_counter / (time.time()-start_time))\n",
    "cv2.destroyAllWindows()\n",
    "# always reset frame from capture at the end to avoid incorrect skips during access\n",
    "cap.set(1, 0)\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to **compare the detections** to the **ground truth** of each frame, we need to compare every detection to every ground truth instance. This may be computationally expensive, but it ensures all detections are considered. The process can be easiliy multi threaded if desired as each frame is compare independently of the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processed frames:\",len(all_detection_centres))\n",
    "from scipy.spatial import distance\n",
    "\n",
    "max_detection_distance_px = 50# only detections closer than X px away from the centre of a ground truth track are considered correct detections\n",
    "\n",
    "total_gt_detections = 0 # number of total detections in the ground truth dataset\n",
    "total_missed_detections = 0 # number of missed detections which are present in the groud truth dataset\n",
    "total_false_positives = 0 # number of incorrect detections that do not match any groud thruth tracks\n",
    "all_frame_detection_deviations = [] # list of mean pixel deviations for correct detections\n",
    "\n",
    "def compare_points(gt,detection, max_dist=25):\n",
    "    match = False\n",
    "    px_distance = distance.euclidean(gt, detection)\n",
    "    if px_distance <= max_dist:\n",
    "        match = True\n",
    "    return match, px_distance\n",
    "\n",
    "def compare_frame(frame_gt, frame_detections, max_dist=50):\n",
    "    gt_detections = int((np.count_nonzero(frame_gt!=0) - 1) / 2)\n",
    "    matches_gt = np.ones(gt_detections)\n",
    "    matches_det = np.ones(len(frame_detections))\n",
    "    detection_distances = []\n",
    "    # now strip all empty entries from the ground truth\n",
    "    frame_gt = frame_gt[frame_gt != 0]\n",
    "    for i in range(len(matches_gt)):\n",
    "        min_dist = 9999\n",
    "        for j in range(len(matches_det)):\n",
    "            match, px_dist = compare_points(gt=frame_gt[(i*2)+1:(i*2)+3], detection=frame_detections[j], max_dist=max_dist)\n",
    "            if match:\n",
    "                matches_gt[i] = 0\n",
    "                matches_det[j] = 0\n",
    "                if px_dist < min_dist:\n",
    "                    min_dist = px_dist\n",
    "        if min_dist < 9999:\n",
    "            detection_distances.append(min_dist)\n",
    "            \n",
    "    missed_detections = int(np.sum(matches_gt))\n",
    "    false_positives = int(np.sum(matches_det))\n",
    "    if len(detection_distances) == 0:\n",
    "        mean_detection_distance = 0\n",
    "    else:\n",
    "        mean_detection_distance = np.mean(np.array(detection_distances))\n",
    "    \n",
    "    return gt_detections, missed_detections, false_positives, mean_detection_distance\n",
    "\n",
    "for f, detections in enumerate(all_detection_centres):\n",
    "    gt_detections, missed_detections, false_positives, mean_detection_distance = compare_frame(frame_gt=tracks[0][f], frame_detections=detections, max_dist=max_detection_distance_px)\n",
    "    total_gt_detections += gt_detections\n",
    "    total_missed_detections += missed_detections\n",
    "    total_false_positives += false_positives\n",
    "    all_frame_detection_deviations.append(mean_detection_distance)\n",
    "    \n",
    "mean_px_error = np.mean(all_frame_detection_deviations)\n",
    "detection_accuracy = ((total_gt_detections - total_missed_detections - total_false_positives) / total_gt_detections) * 100\n",
    "    \n",
    "print(\"Total ground truth detections:\",total_gt_detections)\n",
    "print(\"Total missed detections:\",total_missed_detections)\n",
    "print(\"Total false positives:\",total_false_positives)\n",
    "print(\"Detection accuracy (GT - FP - MD) / GT):\", np.round(detection_accuracy, 1),\"%\")\n",
    "print(\"Mean pixel error:\", np.round(mean_px_error,3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all detections into a single 2D array to produce a simple scatter plot\n",
    "all_xy = []\n",
    "for frame in all_detection_centres:\n",
    "    for detection in frame:\n",
    "        all_xy.append(detection)\n",
    "        \n",
    "all_xy = np.array(all_xy)\n",
    "all_xy = np.reshape(all_xy, (-1,2)) # ensures the format can be read by matplotlib\n",
    "\n",
    "plt.scatter(all_xy[:,0],all_xy[:,1],s=0.1)\n",
    "plt.title(\"Detections\")    \n",
    "plt.xlabel(\"X axis [px]\")   \n",
    "plt.ylabel(\"Y axis [px]\")\n",
    "plt.xlim(0,frame_rgb.shape[1])\n",
    "plt.ylim(0,frame_rgb.shape[0])\n",
    "plt.savefig(\"I:/BENCHMARK/sub_colony_tracking/RESULTS/\" + video[:-4].split(\"/\")[-1] + \"_\" + \n",
    "            yolo_cfg.split(\"_\")[-1][:-4] +'_detections.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
