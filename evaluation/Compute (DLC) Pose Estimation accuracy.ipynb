{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute (DLC) Pose Estimation accuracy\n",
    "First, we'll import the hand labeled ground truth files.\n",
    "\n",
    "This notebook is designed to work with the standard folder structure found in [DeepLabCut](https://github.com/DeepLabCut/DeepLabCut) projects. We are going to be using our own custom functions for evaluation here, so we're going to use DLC-Live so we can point to individual images rather than entire datasets with a subsection of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlclive import DLCLive, Processor\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "\"\"\"\n",
    "To install tqdm (to display progress bars in jupyter) run the following commands in your environment:\n",
    "\n",
    "1. conda install -c conda-forge tqdm   # conda\n",
    "2. pip install ipywidgets\n",
    "3. jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "dlc_proc = Processor()\n",
    "dlc_trained_model_path = \"F:/OmniTrax_WIP/DLC/DLC_multi_stick_v1_resnet_50_iteration-0_shuffle-1/\"\n",
    "dlc_live = DLCLive(dlc_trained_model_path, processor=dlc_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's load all the data we want to evaluate!\n",
    "\n",
    "This script needs to point at the location of the \"labeled-data\" folder of your DLC project, expecting the hierachy:\n",
    "\n",
    "***labeled-data/VIDEOS/CollectedData_USER.h5***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "labeled_data_path = Path(\"C:/Users/Legos/Documents/PhD/Blender/OmniTrax/OmniTrax_WIP/benchmark/STICK_DLC/\")\n",
    "\n",
    "# grab all h5 files\n",
    "first_h5_found = False\n",
    "for subdir, dirs, files in os.walk(labeled_data_path):\n",
    "    for file in files:\n",
    "        if file[-1] == \"5\":\n",
    "            if not first_h5_found:\n",
    "                df_labeled = pd.read_hdf(os.path.join(subdir, file))\n",
    "                first_h5_found = True\n",
    "            else:\n",
    "                more_labeled = pd.read_hdf(os.path.join(subdir, file))\n",
    "                df_labeled = df_labeled.append(more_labeled)\n",
    "\n",
    "df_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# let's check the labels of the imported annotated data\n",
    "import numpy as np\n",
    "point_size = 5\n",
    "\n",
    "for item in df_labeled.iterrows():\n",
    "    img_name = item[0]\n",
    "    img_path = os.path.join(labeled_data_path,img_name)\n",
    "    img = cv2.imread(str(img_path))\n",
    "    \n",
    "    \"\"\"\n",
    "    for coord in range(int((len(item[1])) / 2)):\n",
    "        if not np.isnan(item[1][coord*2]) and not np.isnan(item[1][coord*2 + 1]):\n",
    "            img = cv2.circle(img, (int(item[1][coord*2]), int(item[1][coord*2 + 1])),\n",
    "                                       point_size,\n",
    "                                       (int(255 * coord / 49), int(255 - 255 * coord / 49), 200), -1)\n",
    "                   \n",
    "    cv2.imshow(\"DLC Labeled IMG\",img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \"\"\"\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialise** the network with the desired input shape. Afterwards the network can be used for inference on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#desired_dims = (int(1024 /2),int(768 /2)) # quarter\n",
    "#desired_dims = (1024,768) # half\n",
    "desired_dims = (1024* 2,768* 2) # full\n",
    "\n",
    "dlc_test_image_path = img_path\n",
    "\n",
    "dlc_test_image = cv2.imread(dlc_test_image_path)\n",
    "dlc_test_image_resized = cv2.resize(dlc_test_image,desired_dims)\n",
    "\n",
    "dlc_live.init_inference(dlc_test_image_resized)\n",
    "\n",
    "scale_factor = (desired_dims[0] / dlc_test_image.shape[1] + \n",
    "                desired_dims[1] / dlc_test_image.shape[0]) /2\n",
    "\n",
    "print(\"Running inference at scale factor : \", scale_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, now let's check how well our trained network performs.\n",
    "\n",
    "If desired, add a lookup-table to only evaluate performance on specific landmarks. This can be useful when there is a discrepancy between which landmarks have been labeled in the real vs synthetic datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thresh = 0.25\n",
    "point_size = 5\n",
    "\n",
    "all_poses = [] # estimated landmark positions\n",
    "all_scaled_poses = [] # rescaled to original resolution of labeled data\n",
    "show_outputs = True\n",
    "\n",
    "# optional landmark lookup table. denote skips with -1\n",
    "\"\"\"\n",
    "ID_lookup = [61,55,49,0,-1,-1,-1,3,5,-1,28,29,30,31,32,33,\n",
    "             35,36,37,38,39,40,42,43,44,45,46,47,\n",
    "             7,8,9,10,11,12,14,15,16,17,18,19,21,22,23,24,25,26]\n",
    "\"\"\"             \n",
    "ID_lookup = [-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,\n",
    "             29,30,31,32,33,34,\n",
    "             36,37,38,39,40,41,\n",
    "             43,44,45,46,47,48,\n",
    "             8,9,10,11,12,13,\n",
    "             15,16,17,18,19,20,\n",
    "             22,23,24,25,26,27]\n",
    "\n",
    "pose_error = np.ones((len(df_labeled.index),len(ID_lookup))) * -1\n",
    "\n",
    "print(\"Running inference...\")\n",
    "\n",
    "for i, item in tqdm(enumerate(df_labeled.iterrows()),total=len(df_labeled.index)):\n",
    "    img_name = item[0]\n",
    "    img_path = os.path.join(labeled_data_path,img_name)\n",
    "    \n",
    "    dlc_image = cv2.imread(img_path)\n",
    "    dlc_image_resized = cv2.resize(dlc_image,desired_dims)\n",
    "\n",
    "    pose = dlc_live.get_pose(dlc_image_resized)\n",
    "    \n",
    "    scaled_pose = pose.copy()\n",
    "    for p, point in enumerate(pose):\n",
    "\n",
    "        if show_outputs:\n",
    "            if point[2] >= thresh:\n",
    "                dlc_test_image_resized = cv2.circle(dlc_image_resized, (int(point[0]), int(point[1])),\n",
    "                                           point_size,\n",
    "                                           (int(255 * p / 49), int(255 - 255 * p / 49), 200), -1)\n",
    "        \n",
    "        # the shape of the image is returned in y , x, color\n",
    "        p_x_scaled = (point[0] / desired_dims[0]) * dlc_image.shape[1]\n",
    "        p_y_scaled = (point[1] / desired_dims[1]) * dlc_image.shape[0]\n",
    "\n",
    "        scaled_pose[p][0:2] = p_x_scaled, p_y_scaled\n",
    "        \n",
    "        if p in ID_lookup and ID_lookup.index(p) != -1:\n",
    "            if not pd.isnull(df_labeled.iloc[i,ID_lookup.index(p)*2]):\n",
    "                if point[2] >= thresh:\n",
    "                    #rint(scaled_pose[p][0:2],df_labeled.iloc[i,ID_lookup.index(p)*2], df_labeled.iloc[i,ID_lookup.index(p)*2 + 1])\n",
    "                    pose_error[i,ID_lookup.index(p)] = np.linalg.norm(scaled_pose[p][0:2] - np.array([df_labeled.iloc[i,ID_lookup.index(p)*2], df_labeled.iloc[i,ID_lookup.index(p)*2 + 1]]))\n",
    "        \n",
    "    if show_outputs:\n",
    "        cv2.imshow(\"DLC Predicted IMG\",dlc_image_resized)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            show_outputs = False\n",
    "            cv2.destroyAllWindows()\n",
    "    \n",
    "    all_poses.append(pose)\n",
    "    all_scaled_poses.append(scaled_pose)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# ignore unassigned values when computing pose error\n",
    "pose_error = np.where(pose_error == -1, np.nan, pose_error)\n",
    "mean_pose_error = np.nanmean(pose_error)\n",
    "\n",
    "print(\"\\nMean Pose Error [px] :\", round(mean_pose_error,3), \" (at ground truth scale)\")\n",
    "print(\"Mean Pose Error [px] :\", round(mean_pose_error * scale_factor,3), \" (at inference scale)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "per_part_MPE = np.nanmean(pose_error * scale_factor,axis=0)\n",
    "for k, key in enumerate(df_labeled.keys()):\n",
    "    if k % 2 == 0:\n",
    "        if not ID_lookup[int(k / 2)] == -1:\n",
    "            #print(int(k / 2), key[1], abs(round(per_part_MPE[int(k / 2)],2)))\n",
    "            print(abs(round(per_part_MPE[int(k / 2)],2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"C:/Users/Legos/Desktop/SICB-2022/Poster/DATA/STICK_VIEW.png\"\n",
    "desired_dims = (1189,841) # full\n",
    "\n",
    "dlc_test_image_path = img_path\n",
    "\n",
    "dlc_test_image = cv2.imread(dlc_test_image_path)\n",
    "dlc_test_image_resized = cv2.resize(dlc_test_image,desired_dims)\n",
    "\n",
    "dlc_live.init_inference(dlc_test_image_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc_image_resized = dlc_test_image_resized.copy()\n",
    "pose = dlc_live.get_pose(dlc_image_resized)\n",
    "\n",
    "thresh = 0.0    \n",
    "point_size = 4\n",
    "\n",
    "for p, point in enumerate(pose):\n",
    "    if point[2] >= thresh:\n",
    "        dlc_test_image_resized = cv2.circle(dlc_image_resized, (int(point[0]), int(point[1])),\n",
    "                                   point_size,\n",
    "                                   (int(255 * p / 49), int(255 - 255 * p / 49), 200), -1)\n",
    "\n",
    "cv2.imshow(\"DLC Predicted IMG\",dlc_image_resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
