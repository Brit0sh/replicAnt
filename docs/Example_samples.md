# replicAnt

"generating annotated images of animals in complex environments with Unreal Engine"

by [Fabian **Plum**](https://twitter.com/fabian_plum),
[René **Bulla**](https://twitter.com/renebulla),
[Hendrik **Beck**](https://twitter.com/Hendrik_Beck),
[Natalie **Imirzian**](https://twitter.com/nimirzy),
and [David **Labonte**](https://twitter.com/EvoBiomech) (2023)

___

![](../images/06_launch_better_together.png)

___

## Example samples

### _Atta vollenweideri_ - multi model:

The following samples are part of the datasets used to train detection, semantic segmentation, and classifier networks, as
presented in [***replicAnt* - generating annotated images of animals in complex environments with Unreal
Engine**](https://www.biorxiv.org/content/10.1101/2023.04.20.537685v1)

<table style="padding:10px">
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=1OHvbXQZirAnkj_3bILVSG0Q5EaxojxeK" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1lD0omQ8BLo-eLu7_M1AuLLwDZ6TxWM0z" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1YVgrDgahyWLlJ0ZYqEM_dk_jWen9Ecjy" width = 500px ></td>
  </tr>
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=1o7cZqfvjDlcYABB9wJHzZ2ONPCfZ2tiX" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1VYvOXCHaEHSKbYL4xwzQz6jbX7NSU6bC" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1_CRCO9qYTbA4RwF1UqmwWsoZ8bbgKdoH" width = 500px ></td>
  </tr>
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=1yEuwJCk0qPWQfbWdWDmDExMDwGMMQxJF" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1X2KfDIcLrJiEhFpv8pXYjDgptAn2O4gl" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1BZqVD8fokAhaXNO2aVTcW2yRVR4ECwcc" width = 500px ></td>
  </tr>
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=1cJEIdtVtExrik4T1ziiSDVDkoyHPYvjZ" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1e5NBGGSX5IPpuzI4FMJa0phZldDPlcxf" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1bDIMb_Je28BX8ONUwZ8UYzlE1Ug3vBJ-" width = 500px ></td>
  </tr>
</table>

### _Sungaya inexpectata_ - single model:

The following samples are part of the datasets used to pose estimation networks, as
presented in [***replicAnt* - generating annotated images of animals in complex environments with Unreal
Engine**](https://www.biorxiv.org/content/10.1101/2023.04.20.537685v1). DeepLabCut annotation conventions displayed 
below each sample

<table style="padding:10px">
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=1WEKeCQMyg3dr77bYzc0wyMfX1ANVpjMU" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1pTLOpi3jIPM0WMx9MH6h4tzIIkcCl8_o" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1IR1_DVslj-f2KiNJv6Q4tIiPWtf4Qg_B" width = 500px ></td>
  </tr>
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=174AAXkx_voL7Nbivr5Xz6dSIEElLBtcg" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1_e8myztRpVj1ZVk7HUe-wEl0vjZesFRs" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1VR5ej-FlFWew1oH5u3LBOioWrEQLHpJD" width = 500px ></td>
  </tr>
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=1kbhfHeHn9edfhVaJjGn9bbchrIqqL9sb" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1rXv1Is79vt9_qpjxCShK74oIPsRnDViN" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1yoLLOaRhzKqzVO_uC8aDgypImqLUk0N-" width = 500px ></td>
  </tr>
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=1Re4wpU5zlgU_R24-Xg_uNEvWk8CHAYSS" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1VwePNNyjGNChEtfy9-wLpCxk_gMCaY3A" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1lUuspt_oMF3q1i7Hc5Wpx561juPi0XKD" width = 500px ></td>
  </tr>
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=1xLaNd4MXaiBGJBgz0s3qTcypXGNdiQrB" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=14bqfFZHvdkDBU0kNybtIx5NjX_3Ur8H9" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1TNKBlzZTqDN_7Qc3JPLHci5ZpzKjfY_B" width = 500px ></td>
  </tr>
  <tr> 
   <td><img src="https://drive.google.com/uc?export=view&id=1i-kHUNRQXTj7fJ9lW9G22dAKqc2Hyo-m" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1rbsHBYwa1RMV8RBwFQ2Fhiyxavzp3vwo" width = 500px ></td>
   <td><img src="https://drive.google.com/uc?export=view&id=1I-gQUIGNRH7_rkBD9yUYRRplb6VLtOwA" width = 500px ></td>
  </tr>
</table>

---

### Official full datasets:

All datasets, both generated and real, additional SI, and the best performing networks are hosted via Zenodo:

* 3D Models https://zenodo.org/record/7849059 **DOI** : 10.5281/zenodo.7849059
* Detection and Tracking Datasets and Trained networks https://zenodo.org/record/7849417 **DOI** :
  10.5281/zenodo.7849417
* Pose-Estimation Datasets and Trained networks https://zenodo.org/record/7849596 **DOI** : 10.5281/zenodo.7849596
* Semantic And Instance Segmentation Datasets and Trained networks https://zenodo.org/record/7849570 **DOI** :
  10.5281/zenodo.7849570

___

> In case you encounter any problems, consult our [troubleshooting guide](troubleshooting.md), or consider raising an
> **issue** on the replicAnt GitHub page.

## License

© Fabian Plum, Rene Bulla, David Labonte 2023
[MIT License](https://choosealicense.com/licenses/mit/)
