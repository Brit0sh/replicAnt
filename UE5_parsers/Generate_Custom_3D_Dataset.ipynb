{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This script is used to automatically generate custom datasets to support object detection as well as 3D and 2D pose estimation, including camera data.\n",
    "\n",
    "**WARNING :** In this version, restrict the **Colony size** to a **maxmimum of 1 indivudal**!\n",
    "\n",
    "Ensure, that your **GPU** has sufficient **memory** for the chosen resolution! \n",
    "\n",
    "The script **excludes empty samples** (*no detections present*) automatically and provide an additional **occlusion vector**, indicating whether a key point is visible (1) or occluded (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41 files...\n",
      "reading ColonieInfo.csv\n",
      "Loaded colony file with seed  123 and 1 individual(s).\n",
      "Generating single-animal dataset!\n"
     ]
    }
   ],
   "source": [
    "# define location of dataset and return all files\n",
    "dataset_location = \"example_data/_input_single/\"\n",
    "target_dir = \"example_data/3D/\"\n",
    "all_files = [f for f in listdir(dataset_location) if isfile(join(dataset_location, f))]\n",
    "\n",
    "# next, sort files into images, depth maps, segmentation maps, data, and colony info\n",
    "dataset_img = []\n",
    "dataset_depth = []\n",
    "dataset_seg = []\n",
    "dataset_data = []\n",
    "dataset_colony = dataset_location + \"/ColonieInfo.csv\"\n",
    "\n",
    "for file in all_files:\n",
    "    loc = dataset_location + \"/\" + file\n",
    "    if file[-7:-4] == \"Img\":\n",
    "        dataset_img.append(loc)\n",
    "    elif file[-7:-4] == \"Seg\":\n",
    "        dataset_seg.append(loc)\n",
    "    elif file[-8:-4] == \"Depth\":\n",
    "        dataset_depth.append(loc)\n",
    "    elif file[-8:-4] == \"Data\":\n",
    "        dataset_data.append(loc)\n",
    "        \n",
    "print(\"Found\",len(all_files),\"files...\")\n",
    "\n",
    "# next sort the colony info into its IDs to determine the colony size and individual scales\n",
    "# one entry for each successive ID is read\n",
    "from csv import reader\n",
    "\n",
    "colony = {'seed': 0,\n",
    "            'ID': [],\n",
    "         'scale': []}\n",
    "\n",
    "with open(dataset_colony, 'r') as colony_file:\n",
    "        print(\"reading\", file)\n",
    "        # pass the file object to reader() to get the reader object\n",
    "        csv_reader = reader(colony_file)\n",
    "        # iterate over each row in the csv using reader object\n",
    "        for r, row in enumerate(csv_reader):\n",
    "            if r == 0:\n",
    "                colony['seed'] = row[0].split(\"=\")[-1]\n",
    "            else:\n",
    "                colony['ID'].append(row[0].split(\"=\")[-1])\n",
    "                colony['scale'].append(row[1].split(\"=\")[-1])\n",
    "\n",
    "print(\"Loaded colony file with seed\",colony['seed'],\"and\",len(colony['ID']),\"individual(s).\")\n",
    "if len(colony['ID']) == 1:\n",
    "    multi_animal = False\n",
    "    print(\"Generating single-animal dataset!\")\n",
    "else:\n",
    "    multi_animal = True\n",
    "    print(\"WARNING! Multi-animal datasets are currently NOT supported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the cleaned colony info, we can start loading the data associated with each frame.\n",
    "For simplicity, we will produce a list of lists, containing all individuals and their attributes for each frame.\n",
    "\n",
    "We will therefore access \"data\" as **[frame] [individual] [attribute]**, where attributes will include [ID,bbox_x_0,bbox_y_0,...]\n",
    "\n",
    "The data files additionally contain **camera information**, such as **transformation**, **rotation**, and **intrinsics**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The dataset has a total of 10 generated frames.\n",
      "\n",
      "Found camera data for the following attributes:\n",
      " ['camera_projection:', '[-0.167203 0.957049 0.236853 0] [0.850253 0.0183556 0.526053 0] [0.499112 0.289343 -0.816804 0] [984.281 -1484.85 2961.02 1] ', 'camera_fx', 'camera_fy', 'camera_cx', 'camera_cy'] \n",
      "\n",
      "example camera data of 10_Data.csv :\n",
      " ['[-0.167203 0.957049 0.236853 0] [0.850253 0.0183556 0.526053 0] [0.499112 0.289343 -0.816804 0] [984.281 -1484.85 2961.02 1] ', 2080.000244, 2080.000244, 416.0, 416.0]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "camera_data = []\n",
    "\n",
    "# get the types of camera information stored\n",
    "camera_data_types = []\n",
    "with open(dataset_data[0], 'r') as read_obj:\n",
    "    csv_reader = reader(read_obj)\n",
    "    for row in csv_reader:\n",
    "        # check if the line contains camera or individual data\n",
    "        if row[0][:3] == \"cam\":\n",
    "            for elem in row:\n",
    "                camera_data_types.append(elem.split(\"=\")[0])\n",
    "\n",
    "for file in dataset_data:\n",
    "    # store all returned coordinates for each individual\n",
    "    coords = []\n",
    "    camera_attributes = []    \n",
    "    # open file in read mode\n",
    "    with open(file, 'r') as read_obj:\n",
    "        #print(\"reading\", file)\n",
    "        # pass the file object to reader() to get the reader object\n",
    "        csv_reader = reader(read_obj)\n",
    "        # iterate over each row in the csv using reader object\n",
    "        for row in csv_reader:\n",
    "            # check if the line contains camera or individual data\n",
    "            camera_attributes = []\n",
    "            if row[0][:3] == \"cam\":\n",
    "                for elem in row:\n",
    "                    try:\n",
    "                        camera_attributes.append(float(elem.split(\"=\")[-1]))\n",
    "                    except ValueError:\n",
    "                        if elem[0] == \"[\":\n",
    "                            camera_attributes.append(elem)\n",
    "                camera_data.append(camera_attributes)\n",
    "                \n",
    "            else:\n",
    "                individual = [float(row[0].split(\".\")[0])]\n",
    "                # row variable is a list that represents a row in csv\n",
    "                for elem in row:\n",
    "                    try:\n",
    "                        individual.append(float(elem.split(\"=\")[-1]))\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "                coords.append(individual)\n",
    "        \n",
    "    data.append(coords)\n",
    "\n",
    "# now let's quickly return if the dataset contains what we were looking for    \n",
    "print(\"\\nThe dataset has a total of\", len(data),\"generated frames.\\n\")\n",
    "\n",
    "if len(camera_data) != 0:\n",
    "    print(\"Found camera data for the following attributes:\\n\",camera_data_types,\"\\n\")\n",
    "    print(\"example camera data of\",dataset_data[0].split(\"/\")[-1],\":\\n\",camera_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there may be animals for which we don't use all bones we can return a list of all labels and exclude the respective locations from the pose data. As all animals use the same convention, we can simply read in one example and remove the corresponding indices from all animals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading example_data/_input_single//10_Data.csv\n",
      "\n",
      "All labels:\n",
      "['0.BoundingBox.BoundMin.X', 'BoundingBox.BoundMin.Y', 'BoundingBox.BoundMax.X', 'BoundingBox.BoundMax.Y', 'b_t.X', 'b_t.Y', 'b_t.X_world', 'b_t.Y_world', 'b_t.Z_world', 'b_a_1.X', 'b_a_1.Y', 'b_a_1.X_world', 'b_a_1.Y_world', 'b_a_1.Z_world', 'b_a_2.X', 'b_a_2.Y', 'b_a_2.X_world', 'b_a_2.Y_world', 'b_a_2.Z_world', 'b_a_3.X', 'b_a_3.Y', 'b_a_3.X_world', 'b_a_3.Y_world', 'b_a_3.Z_world', 'b_a_4.X', 'b_a_4.Y', 'b_a_4.X_world', 'b_a_4.Y_world', 'b_a_4.Z_world', 'b_a_5.X', 'b_a_5.Y', 'b_a_5.X_world', 'b_a_5.Y_world', 'b_a_5.Z_world', 'b_a_5_end.X', 'b_a_5_end.Y', 'b_a_5_end.X_world', 'b_a_5_end.Y_world', 'b_a_5_end.Z_world', 'l_1_co_r.X', 'l_1_co_r.Y', 'l_1_co_r.X_world', 'l_1_co_r.Y_world', 'l_1_co_r.Z_world', 'l_1_tr_r.X', 'l_1_tr_r.Y', 'l_1_tr_r.X_world', 'l_1_tr_r.Y_world', 'l_1_tr_r.Z_world', 'l_1_fe_r.X', 'l_1_fe_r.Y', 'l_1_fe_r.X_world', 'l_1_fe_r.Y_world', 'l_1_fe_r.Z_world', 'l_1_ti_r.X', 'l_1_ti_r.Y', 'l_1_ti_r.X_world', 'l_1_ti_r.Y_world', 'l_1_ti_r.Z_world', 'l_1_ta_r.X', 'l_1_ta_r.Y', 'l_1_ta_r.X_world', 'l_1_ta_r.Y_world', 'l_1_ta_r.Z_world', 'l_1_pt_r.X', 'l_1_pt_r.Y', 'l_1_pt_r.X_world', 'l_1_pt_r.Y_world', 'l_1_pt_r.Z_world', 'l_1_pt_r_end.X', 'l_1_pt_r_end.Y', 'l_1_pt_r_end.X_world', 'l_1_pt_r_end.Y_world', 'l_1_pt_r_end.Z_world', 'l_2_co_r.X', 'l_2_co_r.Y', 'l_2_co_r.X_world', 'l_2_co_r.Y_world', 'l_2_co_r.Z_world', 'l_2_tr_r.X', 'l_2_tr_r.Y', 'l_2_tr_r.X_world', 'l_2_tr_r.Y_world', 'l_2_tr_r.Z_world', 'l_2_fe_r.X', 'l_2_fe_r.Y', 'l_2_fe_r.X_world', 'l_2_fe_r.Y_world', 'l_2_fe_r.Z_world', 'l_2_ti_r.X', 'l_2_ti_r.Y', 'l_2_ti_r.X_world', 'l_2_ti_r.Y_world', 'l_2_ti_r.Z_world', 'l_2_ta_r.X', 'l_2_ta_r.Y', 'l_2_ta_r.X_world', 'l_2_ta_r.Y_world', 'l_2_ta_r.Z_world', 'l_2_pt_r.X', 'l_2_pt_r.Y', 'l_2_pt_r.X_world', 'l_2_pt_r.Y_world', 'l_2_pt_r.Z_world', 'l_2_pt_r_end.X', 'l_2_pt_r_end.Y', 'l_2_pt_r_end.X_world', 'l_2_pt_r_end.Y_world', 'l_2_pt_r_end.Z_world', 'l_3_co_r.X', 'l_3_co_r.Y', 'l_3_co_r.X_world', 'l_3_co_r.Y_world', 'l_3_co_r.Z_world', 'l_3_tr_r.X', 'l_3_tr_r.Y', 'l_3_tr_r.X_world', 'l_3_tr_r.Y_world', 'l_3_tr_r.Z_world', 'l_3_fe_r.X', 'l_3_fe_r.Y', 'l_3_fe_r.X_world', 'l_3_fe_r.Y_world', 'l_3_fe_r.Z_world', 'l_3_ti_r.X', 'l_3_ti_r.Y', 'l_3_ti_r.X_world', 'l_3_ti_r.Y_world', 'l_3_ti_r.Z_world', 'l_3_ta_r.X', 'l_3_ta_r.Y', 'l_3_ta_r.X_world', 'l_3_ta_r.Y_world', 'l_3_ta_r.Z_world', 'l_3_pt_r.X', 'l_3_pt_r.Y', 'l_3_pt_r.X_world', 'l_3_pt_r.Y_world', 'l_3_pt_r.Z_world', 'l_3_pt_r_end.X', 'l_3_pt_r_end.Y', 'l_3_pt_r_end.X_world', 'l_3_pt_r_end.Y_world', 'l_3_pt_r_end.Z_world', 'w_1_r.X', 'w_1_r.Y', 'w_1_r.X_world', 'w_1_r.Y_world', 'w_1_r.Z_world', 'w_1_r_end.X', 'w_1_r_end.Y', 'w_1_r_end.X_world', 'w_1_r_end.Y_world', 'w_1_r_end.Z_world', 'w_2_r.X', 'w_2_r.Y', 'w_2_r.X_world', 'w_2_r.Y_world', 'w_2_r.Z_world', 'w_2_r_end.X', 'w_2_r_end.Y', 'w_2_r_end.X_world', 'w_2_r_end.Y_world', 'w_2_r_end.Z_world', 'l_1_co_l.X', 'l_1_co_l.Y', 'l_1_co_l.X_world', 'l_1_co_l.Y_world', 'l_1_co_l.Z_world', 'l_1_tr_l.X', 'l_1_tr_l.Y', 'l_1_tr_l.X_world', 'l_1_tr_l.Y_world', 'l_1_tr_l.Z_world', 'l_1_fe_l.X', 'l_1_fe_l.Y', 'l_1_fe_l.X_world', 'l_1_fe_l.Y_world', 'l_1_fe_l.Z_world', 'l_1_ti_l.X', 'l_1_ti_l.Y', 'l_1_ti_l.X_world', 'l_1_ti_l.Y_world', 'l_1_ti_l.Z_world', 'l_1_ta_l.X', 'l_1_ta_l.Y', 'l_1_ta_l.X_world', 'l_1_ta_l.Y_world', 'l_1_ta_l.Z_world', 'l_1_pt_l.X', 'l_1_pt_l.Y', 'l_1_pt_l.X_world', 'l_1_pt_l.Y_world', 'l_1_pt_l.Z_world', 'l_1_pt_l_end.X', 'l_1_pt_l_end.Y', 'l_1_pt_l_end.X_world', 'l_1_pt_l_end.Y_world', 'l_1_pt_l_end.Z_world', 'l_2_co_l.X', 'l_2_co_l.Y', 'l_2_co_l.X_world', 'l_2_co_l.Y_world', 'l_2_co_l.Z_world', 'l_2_tr_l.X', 'l_2_tr_l.Y', 'l_2_tr_l.X_world', 'l_2_tr_l.Y_world', 'l_2_tr_l.Z_world', 'l_2_fe_l.X', 'l_2_fe_l.Y', 'l_2_fe_l.X_world', 'l_2_fe_l.Y_world', 'l_2_fe_l.Z_world', 'l_2_ti_l.X', 'l_2_ti_l.Y', 'l_2_ti_l.X_world', 'l_2_ti_l.Y_world', 'l_2_ti_l.Z_world', 'l_2_ta_l.X', 'l_2_ta_l.Y', 'l_2_ta_l.X_world', 'l_2_ta_l.Y_world', 'l_2_ta_l.Z_world', 'l_2_pt_l.X', 'l_2_pt_l.Y', 'l_2_pt_l.X_world', 'l_2_pt_l.Y_world', 'l_2_pt_l.Z_world', 'l_2_pt_l_end.X', 'l_2_pt_l_end.Y', 'l_2_pt_l_end.X_world', 'l_2_pt_l_end.Y_world', 'l_2_pt_l_end.Z_world', 'l_3_co_l.X', 'l_3_co_l.Y', 'l_3_co_l.X_world', 'l_3_co_l.Y_world', 'l_3_co_l.Z_world', 'l_3_tr_l.X', 'l_3_tr_l.Y', 'l_3_tr_l.X_world', 'l_3_tr_l.Y_world', 'l_3_tr_l.Z_world', 'l_3_fe_l.X', 'l_3_fe_l.Y', 'l_3_fe_l.X_world', 'l_3_fe_l.Y_world', 'l_3_fe_l.Z_world', 'l_3_ti_l.X', 'l_3_ti_l.Y', 'l_3_ti_l.X_world', 'l_3_ti_l.Y_world', 'l_3_ti_l.Z_world', 'l_3_ta_l.X', 'l_3_ta_l.Y', 'l_3_ta_l.X_world', 'l_3_ta_l.Y_world', 'l_3_ta_l.Z_world', 'l_3_pt_l.X', 'l_3_pt_l.Y', 'l_3_pt_l.X_world', 'l_3_pt_l.Y_world', 'l_3_pt_l.Z_world', 'l_3_pt_l_end.X', 'l_3_pt_l_end.Y', 'l_3_pt_l_end.X_world', 'l_3_pt_l_end.Y_world', 'l_3_pt_l_end.Z_world', 'w_1_l.X', 'w_1_l.Y', 'w_1_l.X_world', 'w_1_l.Y_world', 'w_1_l.Z_world', 'w_1_l_end.X', 'w_1_l_end.Y', 'w_1_l_end.X_world', 'w_1_l_end.Y_world', 'w_1_l_end.Z_world', 'w_2_l.X', 'w_2_l.Y', 'w_2_l.X_world', 'w_2_l.Y_world', 'w_2_l.Z_world', 'w_2_l_end.X', 'w_2_l_end.Y', 'w_2_l_end.X_world', 'w_2_l_end.Y_world', 'w_2_l_end.Z_world', 'b_h.X', 'b_h.Y', 'b_h.X_world', 'b_h.Y_world', 'b_h.Z_world', 'ma_r.X', 'ma_r.Y', 'ma_r.X_world', 'ma_r.Y_world', 'ma_r.Z_world', 'ma_r_end.X', 'ma_r_end.Y', 'ma_r_end.X_world', 'ma_r_end.Y_world', 'ma_r_end.Z_world', 'an_1_r.X', 'an_1_r.Y', 'an_1_r.X_world', 'an_1_r.Y_world', 'an_1_r.Z_world', 'an_2_r.X', 'an_2_r.Y', 'an_2_r.X_world', 'an_2_r.Y_world', 'an_2_r.Z_world', 'an_3_r.X', 'an_3_r.Y', 'an_3_r.X_world', 'an_3_r.Y_world', 'an_3_r.Z_world', 'an_3_r_end.X', 'an_3_r_end.Y', 'an_3_r_end.X_world', 'an_3_r_end.Y_world', 'an_3_r_end.Z_world', 'ma_l.X', 'ma_l.Y', 'ma_l.X_world', 'ma_l.Y_world', 'ma_l.Z_world', 'ma_l_end.X', 'ma_l_end.Y', 'ma_l_end.X_world', 'ma_l_end.Y_world', 'ma_l_end.Z_world', 'an_1_l.X', 'an_1_l.Y', 'an_1_l.X_world', 'an_1_l.Y_world', 'an_1_l.Z_world', 'an_2_l.X', 'an_2_l.Y', 'an_2_l.X_world', 'an_2_l.Y_world', 'an_2_l.Z_world', 'an_3_l.X', 'an_3_l.Y', 'an_3_l.X_world', 'an_3_l.Y_world', 'an_3_l.Z_world', 'an_3_l_end.X', 'an_3_l_end.Y', 'an_3_l_end.X_world', 'an_3_l_end.Y_world', 'an_3_l_end.Z_world']\n"
     ]
    }
   ],
   "source": [
    "# first open and read the first line from the first imported data file\n",
    "labels = []\n",
    "entries_found = False\n",
    "entry = 0\n",
    "\n",
    "while not entries_found:\n",
    "    with open(dataset_data[entry], 'r') as read_obj:\n",
    "        print(\"reading\", read_obj.name)\n",
    "        # pass the file object to reader() to get the reader object\n",
    "        csv_reader = reader(read_obj)\n",
    "        row_0 = next(csv_reader)  # gets the first line\n",
    "        # iterate over each row in the csv using reader object\n",
    "        if row_0[0][:3] != \"cam\":\n",
    "            entries_found = True\n",
    "            for elem in row_0:\n",
    "                try:\n",
    "                    labels.append((elem.split(\"=\")[0].split(\"Bone.\")[-1]))\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        else:\n",
    "            print(\"No entries found! Reading next file... \\n\")\n",
    "            entry += 1\n",
    "\n",
    "# show all used labels:\n",
    "print(\"\\nAll labels:\")\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded data and colony info we can start plotting bounding boxes, joint locations, and check if the camera attributes have been exported correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform between sRGB and linear colour space (optional)\n",
    "\n",
    "def to_linear(srgb):\n",
    "    linear = np.float32(srgb) / 255.0\n",
    "    less = linear <= 0.04045\n",
    "    linear[less] = linear[less] / 12.92\n",
    "    linear[~less] = np.power((linear[~less] + 0.055) / 1.055, 2.4)\n",
    "    return linear * 255.0\n",
    "\n",
    "    \n",
    "def from_linear(linear):\n",
    "    srgb = linear.copy()\n",
    "    less = linear <= 0.0031308\n",
    "    srgb[less] = linear[less] * 12.92\n",
    "    srgb[~less] = 1.055 * np.power(linear[~less], 1.0 / 2.4) - 0.055\n",
    "    return srgb * 255.0\n",
    "\n",
    "# and compute the XYZ rotation matrix from roll, pitch, and yaw\n",
    "def get_rotation_matrix(roll,pitch,yaw,degrees=True):\n",
    "    # convert to radian\n",
    "    if degrees:\n",
    "        roll = np.radians(-roll)\n",
    "        pitch = np.radians(pitch)\n",
    "        yaw = np.radians(-yaw)\n",
    "    # roll rotation \n",
    "    Rx = np.array([[1, 0, 0],\n",
    "                   [0,np.cos(roll),-np.sin(roll)],\n",
    "                   [0,np.sin(roll),np.cos(roll)]])\n",
    "    # pitch rotation\n",
    "    Ry = np.array([[np.cos(pitch),0,np.sin(pitch)],\n",
    "                   [0, 1, 0],\n",
    "                   [-np.sin(pitch),0,np.cos(pitch)]])\n",
    "    # yaw rotation\n",
    "    Rz = np.array([[np.cos(yaw),-np.sin(yaw),0],\n",
    "                   [np.sin(yaw),np.cos(yaw),0],\n",
    "                   [0, 0, 1]])\n",
    "    #Rxyz = np.round(np.matmul(np.matmul(Rz,Ry),Rx),3)\n",
    "    Rxyz = Ry @ Rz @ Rx\n",
    "    return Rxyz\n",
    "\n",
    "def parse_projection_components(projection_matrix):\n",
    "    # converts Unreal view projection into rotation and translation components\n",
    "    # first we strip the unreal outputs of anything that isn't formatted to our liking\n",
    "    stripped_data = projection_matrix.replace('[', '').replace(']', '').split(\" \")\n",
    "    # we can exlcude the last entry, as that is just some random empty entry\n",
    "    stripped_data = [float(i) for i in stripped_data[:-2]]\n",
    "    # now, assign the respective transposed values to the rotation...\n",
    "    cam_rot = np.array([[stripped_data[0],stripped_data[4],stripped_data[8]],\n",
    "                        [stripped_data[1],stripped_data[5],stripped_data[9]],\n",
    "                        [stripped_data[2],stripped_data[6],stripped_data[10]]])\n",
    "    # and the translation\n",
    "    cam_trans = np.array([stripped_data[12],stripped_data[13],stripped_data[14]])\n",
    "    # There. Tried to do it differently, had a break down, now it works. \n",
    "    # Bon appetit\n",
    "    return cam_rot,cam_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating 3D pose output files\n",
    "Now comes the difficult part: getting all this data into the required format.\n",
    "\n",
    "We're going to want an **.h5** formatted file, essentially one dataframe for the entire dataset with the following entries:\n",
    "\n",
    "*\t  file_name &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1 string (relative)\n",
    "*\t  rot_mat\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3 x 3 float\n",
    "*\t  trans_mat\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3 x 1 float\n",
    "*\t  intrinsics_mat &nbsp;&nbsp;&nbsp; 3 x 3 float\n",
    "*     bounding_box &nbsp;&nbsp;&nbsp; 4 x 1 float\n",
    "*\t  key_points_3D &nbsp;&nbsp;&nbsp;3 x k float (provide name sheet)\n",
    "*\t  key_points_2D &nbsp;&nbsp;&nbsp;2 x k float\n",
    "*\t  visibility &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1 x k int (0 occluded or 1 visible)\n",
    "\n",
    "To provide visibility info, we will check whether the subject is visbile in the respective segmentation map at the given screen X & Y coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loaded samples: 10\n",
      "Colony size: 1\n",
      "body parts: 70  (including image X & Y, as well as world X Y Z coordinates)\n",
      "\n",
      "Resulting in a dataframe of shape: (10, 8)\n"
     ]
    }
   ],
   "source": [
    "# let's create a big dictionary to store all our dataset info and\n",
    "# save it all to the desired .csv and .h5 files\n",
    "\n",
    "out_df = pd.DataFrame(index=range(len(data)),columns=[\"file_name\",\n",
    "                                                      \"cam_rot\",\n",
    "                                                      \"cam_trans\",\n",
    "                                                      \"cam_intrinsics\",\n",
    "                                                      \"bounding_box\",\n",
    "                                                      \"key_points_3D\",\n",
    "                                                      \"key_points_2D\",\n",
    "                                                      \"visibility\"])\n",
    "#\t- scorer   #(just one, the only scorer is the generator)\n",
    "#\t- - individuals\n",
    "#\t- - - bodyparts\n",
    "#\t- - - - coords\n",
    "\n",
    "print(\"Number of loaded samples:\",len(data))\n",
    "print(\"Colony size:\",len(colony['ID']))\n",
    "print(\"body parts:\",int((len(labels)-4)/5),\" (including image X & Y, as well as world X Y Z coordinates)\\n\")\n",
    "print(\"Resulting in a dataframe of shape:\",out_df.shape)\n",
    "\n",
    "output_file_names = [\"\" for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 12 threads for export...\n",
      "Starting Thread_0\n",
      "Starting Thread_1\n",
      "Starting Thread_2\n",
      "Starting Thread_3\n",
      "Starting Thread_4\n",
      "Starting Thread_5\n",
      "Starting Thread_6\n",
      "Starting Thread_7\n",
      "Starting Thread_8\n",
      "Starting Thread_9\n",
      "Starting Thread_10\n",
      "Starting Thread_11\n",
      "Exiting Thread_1\n",
      "Exiting Thread_3\n",
      "Size mismatch of image and segmentation pass for sample 7_Img.png !\n",
      "Exiting Thread_10\n",
      "Exiting Thread_6\n",
      "Exiting Thread_4\n",
      "Exiting Thread_8\n",
      "Exiting Thread_9\n",
      "Exiting Thread_0\n",
      "Exiting Thread_7\n",
      "Exiting Thread_5\n",
      "Exiting Thread_2\n",
      "Exiting Thread_11\n",
      "Exiting Main export Thread\n",
      "Total time elapsed: 0.37514638900756836 seconds\n"
     ]
    }
   ],
   "source": [
    "# create unique colours for each ID\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# alright. Let's take it from the top and fucking multi-thread this.\n",
    "import threading\n",
    "import queue\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def fix_bounding_boxes(coords,max_val = [1024,1024]):\n",
    "    # fix bounding box coordinates so they do not reach beyond the image\n",
    "    fixed_coords = []\n",
    "    for c, coord in enumerate(coords):\n",
    "        if c == 0 or c == 2:\n",
    "            max_val_temp = max_val[0]\n",
    "        else:\n",
    "            max_val_temp = max_val[1]\n",
    "            \n",
    "        if coord >= max_val_temp:\n",
    "            coord = max_val_temp\n",
    "        elif coord <= 0:\n",
    "            coord = 0\n",
    "        \n",
    "        fixed_coords.append(int(coord))\n",
    "        \n",
    "    return fixed_coords\n",
    "\n",
    "def getThreads():\n",
    "    \"\"\" Returns the number of available threads on a posix/win based system \"\"\"\n",
    "    if sys.platform == 'win32':\n",
    "        return int(os.environ['NUMBER_OF_PROCESSORS'])\n",
    "    else:\n",
    "        return int(os.popen('grep -c cores /proc/cpuinfo').read())\n",
    "\n",
    "class exportThread(threading.Thread):\n",
    "    def __init__(self, threadID, name, q):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.threadID = threadID\n",
    "        self.name = name\n",
    "        self.q = q\n",
    "\n",
    "    def run(self):\n",
    "        print(\"Starting \" + self.name)\n",
    "        process_detections(self.name, self.q)\n",
    "        print(\"Exiting \" + self.name)\n",
    "        \n",
    "def createThreadList(num_threads):\n",
    "    threadNames = []\n",
    "    for t in range(num_threads):\n",
    "        threadNames.append(\"Thread_\" + str(t))\n",
    "\n",
    "    return threadNames\n",
    "\n",
    "def process_detections(threadName, q):\n",
    "    while not exitFlag_export:\n",
    "        queueLock.acquire()\n",
    "        if not workQueue_export.empty():\n",
    "            \n",
    "            data_input = q.get()\n",
    "            i = data_input[0]\n",
    "            img = data_input[1]\n",
    "            queueLock.release()\n",
    "            \n",
    "            display_img = cv2.imread(img)\n",
    "            display_img_orig = display_img.copy()\n",
    "            \n",
    "            img_shape = display_img.shape\n",
    "            \n",
    "            img_name = target_dir + \"/\" + img.split('/')[-1][:-4] + \"_synth\" + \".png\"\n",
    "            # write the file path to the all_points array\n",
    "            output_file_names[i] = img_name\n",
    "            out_df.loc[i][\"file_name\"] = img_name.split(\"/\")[-1]\n",
    "\n",
    "            img_info = []\n",
    "                \n",
    "            # compute visibility for each individual\n",
    "            seg_img = cv2.imread(dataset_seg[i])\n",
    "            seg_img_display = seg_img.copy()\n",
    "            \n",
    "            # set the default visibility to zero to exclude emtpy images\n",
    "            out_df.loc[i][\"visibility\"] = []\n",
    "            \n",
    "            # check if the size of the image and segmentation pass match\n",
    "            if display_img.shape != seg_img.shape:\n",
    "                print(\"Size mismatch of image and segmentation pass for sample\",data_input[1].split(\"/\")[-1],\"!\")\n",
    "                remove_empty_entries.append(i)\n",
    "            else:\n",
    "                for im, individual in enumerate(data[i]):\n",
    "\n",
    "                    bbox = fix_bounding_boxes(individual[1:5],max_val=display_img.shape)\n",
    "                    out_df.loc[i][\"bounding_box\"] = bbox\n",
    "\n",
    "                    # FOR SOME REASON OCCASIONALLY THE ID OF THE SEG FILE IS LOWER THAN THE DATA FILE\n",
    "                    # with: ID = red_channel/255 * im\n",
    "                    # red_channel = (ID/im) * 255\n",
    "                    ID_red_val = int((individual[0]/len(colony['ID']))*255)\n",
    "\n",
    "                    try:\n",
    "                        ID_mask = cv2.inRange(seg_img[bbox[1]:bbox[3],bbox[0]:bbox[2]], np.array([0,0, ID_red_val - 2]), np.array([0,0, ID_red_val + 2]))\n",
    "                        indivual_occupancy = cv2.countNonZero(ID_mask)\n",
    "                    except:\n",
    "                        indivual_occupancy = 1\n",
    "\n",
    "                    #indivual_occupancy = np.count_nonzero((seg_img == [0, 0, int((individual[0]/len(colony['ID']))*255)]).all(axis = 2)) + np.count_nonzero((seg_img == [0, 0, int((individual[0]/len(colony['ID']))*255 - 1)]).all(axis = 2)) + np.count_nonzero((seg_img == [0, 0, int((individual[0]/len(colony['ID']))*255 + 1)]).all(axis = 2))\n",
    "                    bbox_area = abs((bbox[2] - bbox[0]) * (bbox[3] - bbox[1])) + 1\n",
    "                    bbox_occupancy = indivual_occupancy / bbox_area\n",
    "                    #print(\"Individual\", individual[0], \"with bounding box occupancy \",bbox_occupancy)\n",
    "\n",
    "                    # write all camera attributes to the output file\n",
    "                    # for details, refer to https://ksimek.github.io/2013/08/13/intrinsic/\n",
    "\n",
    "                    out_df.loc[i][\"cam_rot\"],out_df.loc[i][\"cam_trans\"] = parse_projection_components(camera_data[i][0])\n",
    "\n",
    "                    out_df.loc[i][\"cam_intrinsics\"] = np.array([[camera_data[i][1],0,camera_data[i][3]],\n",
    "                                                                [0, camera_data[i][2],camera_data[i][4]],\n",
    "                                                                [0,0,1]])\n",
    "\n",
    "                    visbility_img = []\n",
    "                    XY_2D_points = []\n",
    "                    XYZ_3D_points = []\n",
    "\n",
    "                    #cv2.putText(display_img, \"ID: \" + str(int(individual[0])), (bbox[0] + 10,bbox[3] - 10), font, fontScale, fontColor, lineType)\n",
    "                    if bbox_occupancy > visibility_threshold:\n",
    "                        # let's binarise the image and dilate it to make sure all points that visible are found\n",
    "                        seg_bin = cv2.inRange(seg_img, np.array([0,0, ID_red_val - 2]), np.array([0,245, ID_red_val + 2]))\n",
    "                        kernel = np.ones((5,5),np.uint8)\n",
    "                        seg_bin_dilated = cv2.dilate(seg_bin,kernel,iterations = 1)\n",
    "\n",
    "\n",
    "                        for point in range(int(len(individual[5:])/5)):\n",
    "                            if exclude_wings:\n",
    "                                if labels[3 + point*5][0] == \"w\":\n",
    "                                    # skip all entries containing wing data\n",
    "                                    continue\n",
    "\n",
    "                            if individual[point*5 + 5] > img_shape[0] or individual[point*5 + 5] < 0 or individual[point*5 + 6] > img_shape[1] or individual[point*5 + 6] < 0:\n",
    "                                # exclude all points that lie outside the image\n",
    "                                visibility_point = 0\n",
    "                                XY_2D_points.append([0,0])\n",
    "                                XYZ_3D_points.append([0,0,0])\n",
    "                            else:\n",
    "                                # check if the 2D point is occluded in the segmentation image\n",
    "                                # thanks opencv, of course this has to be indexed as Y,X... thanks, really.\n",
    "                                if seg_bin_dilated[int(individual[6 + point*5]),int(individual[5 + point*5])] == 255:                   \n",
    "                                    visibility_point = 1\n",
    "                                    XY_2D_points.append(np.array(individual[5 + point*5 : 7 + point*5]))\n",
    "                                    XYZ_3D_points.append([individual[7 + point*5],\n",
    "                                                          individual[8 + point*5],\n",
    "                                                          individual[9 + point*5]])\n",
    "\n",
    "                                    # draw 2D points for visualisation\n",
    "                                    if len(threadList_export) == 1:\n",
    "                                        seg_img_display = cv2.circle(seg_img_display, (int(individual[5 + point*5]),\n",
    "                                                                                       int(individual[6 + point*5])), \n",
    "                                                                                       radius=0, color=(255, 100, 100), \n",
    "                                                                                       thickness=5)\n",
    "                                else:\n",
    "                                    visibility_point = 0\n",
    "                                    XY_2D_points.append([0,0])\n",
    "                                    XYZ_3D_points.append([0,0,0])\n",
    "\n",
    "                            visbility_img.append(visibility_point)\n",
    "\n",
    "                    if len(threadList_export) == 1:       \n",
    "                        cv2.imshow(\"Segmentation and points\", seg_img_display)\n",
    "                        cv2.imshow(\"Segmentation binarised and dilated\", seg_bin_dilated)\n",
    "                        cv2.waitKey(0) \n",
    "\n",
    "                    out_df.loc[i][\"visibility\"] = visbility_img\n",
    "\n",
    "                # if no entries were found for the respective image, remove it from the output list and don't write out the image\n",
    "                if len(data[i]) == 0 or len(out_df.loc[i][\"visibility\"]) == 0:\n",
    "                    remove_empty_entries.append(i)\n",
    "                else:    \n",
    "                    out_df.loc[i][\"key_points_2D\"] = XY_2D_points\n",
    "                    out_df.loc[i][\"key_points_3D\"] = XYZ_3D_points\n",
    "                    cv2.imwrite(img_name, display_img)\n",
    "\n",
    "        else:\n",
    "            queueLock.release()\n",
    "            \n",
    "# setup as many threads as there are (virtual) CPU cores\n",
    "exitFlag_export = 0\n",
    "# set the following to 1 (instead of getThreads()) to display segmentation maps and visible key points\n",
    "threadList_export = createThreadList(getThreads())\n",
    "print(\"Using\", len(threadList_export), \"threads for export...\")\n",
    "queueLock = threading.Lock()\n",
    "\n",
    "# define paths to all images and set the maximum number of items in the queue equivalent to the number of images\n",
    "workQueue_export = queue.Queue(len(dataset_img))\n",
    "threads = []\n",
    "threadID = 1\n",
    "\n",
    "np.random.seed(seed=1)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 0.5\n",
    "lineType = 2\n",
    "\n",
    "# remove entries that contain no data\n",
    "remove_empty_entries = []\n",
    "\n",
    "# set true if generating dataset for animal without wings\n",
    "exclude_wings = True\n",
    "\n",
    "# we can additionally plot the points in the data files to check joint locations\n",
    "plot_joints = True\n",
    "\n",
    "# remember to refine an export folder when saving out your dataset\n",
    "generate_dataset = True\n",
    "\n",
    "# determine the proportion of a bounding box that needs to be filled before considering the visibility as too low\n",
    "# WARNING: At the moment the ID shown in segmentation maps does not always correspond to the ID in the data file (off by 1)\n",
    "visibility_threshold = 0.001\n",
    "\n",
    "timer = time.time()\n",
    "\n",
    "# Create new threads\n",
    "for tName in threadList_export:\n",
    "    thread = exportThread(threadID, tName, workQueue_export)\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "    threadID += 1\n",
    "\n",
    "# Fill the queue with stacks\n",
    "queueLock.acquire()\n",
    "for i,img in enumerate(dataset_img):\n",
    "    workQueue_export.put([i, img])\n",
    "queueLock.release()\n",
    "\n",
    "# Wait for queue to empty\n",
    "while not workQueue_export.empty():\n",
    "    pass\n",
    "\n",
    "# Notify threads it's time to exit\n",
    "exitFlag_export = 1\n",
    "\n",
    "# Wait for all threads to complete\n",
    "for t in threads:\n",
    "    t.join()\n",
    "print(\"Exiting Main export Thread\")\n",
    "\n",
    "# close all windows if they were opened\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Total time elapsed:\",time.time()-timer,\"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, remove empty entries and dump it all into one **.h5** file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Legos\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\generic.py:2446: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index(['file_name', 'cam_rot', 'cam_trans', 'cam_intrinsics', 'bounding_box',\n",
      "       'key_points_3D', 'key_points_2D', 'visibility'],\n",
      "      dtype='object')]\n",
      "\n",
      "  encoding=encoding,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>cam_rot</th>\n",
       "      <th>cam_trans</th>\n",
       "      <th>cam_intrinsics</th>\n",
       "      <th>bounding_box</th>\n",
       "      <th>key_points_3D</th>\n",
       "      <th>key_points_2D</th>\n",
       "      <th>visibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_Img_synth.png</td>\n",
       "      <td>[[-0.167203, 0.850253, 0.499112], [0.957049, 0...</td>\n",
       "      <td>[984.281, -1484.85, 2961.02]</td>\n",
       "      <td>[[2080.000244, 0.0, 416.0], [0.0, 2080.000244,...</td>\n",
       "      <td>[61, 163, 777, 689]</td>\n",
       "      <td>[[1341.706543, -922.786743, 103.304901], [1447...</td>\n",
       "      <td>[[436.656219, 560.209351], [425.553284, 484.94...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_Img_synth.png</td>\n",
       "      <td>[[-0.159017, 0.516459, 0.841417], [0.986722, 0...</td>\n",
       "      <td>[209.07, -519.595, 7532.0]</td>\n",
       "      <td>[[2080.000244, 0.0, 416.0], [0.0, 2080.000244,...</td>\n",
       "      <td>[328, 418, 557, 637]</td>\n",
       "      <td>[[147.890457, -390.044189, 103.304901], [0, 0,...</td>\n",
       "      <td>[[436.688843, 533.972473], [0, 0], [0, 0], [48...</td>\n",
       "      <td>[1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_Img_synth.png</td>\n",
       "      <td>[[0.658679, 0.151756, 0.736961], [-0.281817, -...</td>\n",
       "      <td>[378.519, -290.607, 8121.7]</td>\n",
       "      <td>[[2080.000244, 0.0, 416.0], [0.0, 2080.000244,...</td>\n",
       "      <td>[422, 251, 616, 515]</td>\n",
       "      <td>[[91.628769, -325.443054, 103.304901], [106.26...</td>\n",
       "      <td>[[532.809753, 414.191132], [526.8479, 394.5438...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3_Img_synth.png</td>\n",
       "      <td>[[0.211941, 0.963012, 0.166402], [0.768035, -0...</td>\n",
       "      <td>[400.37, 307.377, 8268.64]</td>\n",
       "      <td>[[2080.000244, 0.0, 416.0], [0.0, 2080.000244,...</td>\n",
       "      <td>[251, 351, 529, 622]</td>\n",
       "      <td>[[-1002.507141, -427.642151, 103.304901], [-93...</td>\n",
       "      <td>[[359.258789, 494.866608], [384.248596, 488.65...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4_Img_synth.png</td>\n",
       "      <td>[[0.423554, -0.768894, -0.478961], [-0.905236,...</td>\n",
       "      <td>[-108.408, 219.53, 5704.5]</td>\n",
       "      <td>[[2080.000244, 0.0, 416.0], [0.0, 2080.000244,...</td>\n",
       "      <td>[131, 56, 463, 383]</td>\n",
       "      <td>[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [...</td>\n",
       "      <td>[[0, 0], [0, 0], [0, 0], [0, 0], [361.255676, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5_Img_synth.png</td>\n",
       "      <td>[[-0.713143, -0.402388, 0.57403], [-0.695546, ...</td>\n",
       "      <td>[882.988, 134.552, 7810.43]</td>\n",
       "      <td>[[2080.000244, 0.0, 416.0], [0.0, 2080.000244,...</td>\n",
       "      <td>[331, 235, 604, 524]</td>\n",
       "      <td>[[574.686646, 919.362427, 103.304901], [576.41...</td>\n",
       "      <td>[[464.33255, 371.491577], [472.892212, 385.668...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6_Img_synth.png</td>\n",
       "      <td>[[-0.902205, -0.16191, -0.399763], [-0.380167,...</td>\n",
       "      <td>[32.9237, 131.849, 3367.25]</td>\n",
       "      <td>[[2080.000244, 0.0, 416.0], [0.0, 2080.000244,...</td>\n",
       "      <td>[125, 96, 750, 637]</td>\n",
       "      <td>[[-121.864243, -5.426804, 103.304901], [-58.22...</td>\n",
       "      <td>[[481.290253, 268.145294], [458.640228, 329.67...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8_Img_synth.png</td>\n",
       "      <td>[[0.707353, -0.447476, -0.547189], [-0.654724,...</td>\n",
       "      <td>[-84.346, -552.471, 3684.58]</td>\n",
       "      <td>[[2080.000244, 0.0, 416.0], [0.0, 2080.000244,...</td>\n",
       "      <td>[21, 67, 715, 809]</td>\n",
       "      <td>[[-718.752808, -1035.19043, 103.304901], [-625...</td>\n",
       "      <td>[[263.444946, 441.931427], [344.613007, 475.59...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9_Img_synth.png</td>\n",
       "      <td>[[-0.306518, 0.449092, -0.839263], [0.636063, ...</td>\n",
       "      <td>[-636.702, -1758.99, 3443.6]</td>\n",
       "      <td>[[2080.000244, 0.0, 416.0], [0.0, 2080.000244,...</td>\n",
       "      <td>[135, 297, 596, 832]</td>\n",
       "      <td>[[360.448303, 1515.925537, 103.304901], [429.4...</td>\n",
       "      <td>[[306.775391, 680.867188], [329.4422, 606.6062...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          file_name                                            cam_rot  \\\n",
       "0  10_Img_synth.png  [[-0.167203, 0.850253, 0.499112], [0.957049, 0...   \n",
       "1   1_Img_synth.png  [[-0.159017, 0.516459, 0.841417], [0.986722, 0...   \n",
       "2   2_Img_synth.png  [[0.658679, 0.151756, 0.736961], [-0.281817, -...   \n",
       "3   3_Img_synth.png  [[0.211941, 0.963012, 0.166402], [0.768035, -0...   \n",
       "4   4_Img_synth.png  [[0.423554, -0.768894, -0.478961], [-0.905236,...   \n",
       "5   5_Img_synth.png  [[-0.713143, -0.402388, 0.57403], [-0.695546, ...   \n",
       "6   6_Img_synth.png  [[-0.902205, -0.16191, -0.399763], [-0.380167,...   \n",
       "7   8_Img_synth.png  [[0.707353, -0.447476, -0.547189], [-0.654724,...   \n",
       "8   9_Img_synth.png  [[-0.306518, 0.449092, -0.839263], [0.636063, ...   \n",
       "\n",
       "                      cam_trans  \\\n",
       "0  [984.281, -1484.85, 2961.02]   \n",
       "1    [209.07, -519.595, 7532.0]   \n",
       "2   [378.519, -290.607, 8121.7]   \n",
       "3    [400.37, 307.377, 8268.64]   \n",
       "4    [-108.408, 219.53, 5704.5]   \n",
       "5   [882.988, 134.552, 7810.43]   \n",
       "6   [32.9237, 131.849, 3367.25]   \n",
       "7  [-84.346, -552.471, 3684.58]   \n",
       "8  [-636.702, -1758.99, 3443.6]   \n",
       "\n",
       "                                      cam_intrinsics          bounding_box  \\\n",
       "0  [[2080.000244, 0.0, 416.0], [0.0, 2080.000244,...   [61, 163, 777, 689]   \n",
       "1  [[2080.000244, 0.0, 416.0], [0.0, 2080.000244,...  [328, 418, 557, 637]   \n",
       "2  [[2080.000244, 0.0, 416.0], [0.0, 2080.000244,...  [422, 251, 616, 515]   \n",
       "3  [[2080.000244, 0.0, 416.0], [0.0, 2080.000244,...  [251, 351, 529, 622]   \n",
       "4  [[2080.000244, 0.0, 416.0], [0.0, 2080.000244,...   [131, 56, 463, 383]   \n",
       "5  [[2080.000244, 0.0, 416.0], [0.0, 2080.000244,...  [331, 235, 604, 524]   \n",
       "6  [[2080.000244, 0.0, 416.0], [0.0, 2080.000244,...   [125, 96, 750, 637]   \n",
       "7  [[2080.000244, 0.0, 416.0], [0.0, 2080.000244,...    [21, 67, 715, 809]   \n",
       "8  [[2080.000244, 0.0, 416.0], [0.0, 2080.000244,...  [135, 297, 596, 832]   \n",
       "\n",
       "                                       key_points_3D  \\\n",
       "0  [[1341.706543, -922.786743, 103.304901], [1447...   \n",
       "1  [[147.890457, -390.044189, 103.304901], [0, 0,...   \n",
       "2  [[91.628769, -325.443054, 103.304901], [106.26...   \n",
       "3  [[-1002.507141, -427.642151, 103.304901], [-93...   \n",
       "4  [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [...   \n",
       "5  [[574.686646, 919.362427, 103.304901], [576.41...   \n",
       "6  [[-121.864243, -5.426804, 103.304901], [-58.22...   \n",
       "7  [[-718.752808, -1035.19043, 103.304901], [-625...   \n",
       "8  [[360.448303, 1515.925537, 103.304901], [429.4...   \n",
       "\n",
       "                                       key_points_2D  \\\n",
       "0  [[436.656219, 560.209351], [425.553284, 484.94...   \n",
       "1  [[436.688843, 533.972473], [0, 0], [0, 0], [48...   \n",
       "2  [[532.809753, 414.191132], [526.8479, 394.5438...   \n",
       "3  [[359.258789, 494.866608], [384.248596, 488.65...   \n",
       "4  [[0, 0], [0, 0], [0, 0], [0, 0], [361.255676, ...   \n",
       "5  [[464.33255, 371.491577], [472.892212, 385.668...   \n",
       "6  [[481.290253, 268.145294], [458.640228, 329.67...   \n",
       "7  [[263.444946, 441.931427], [344.613007, 475.59...   \n",
       "8  [[306.775391, 680.867188], [329.4422, 606.6062...   \n",
       "\n",
       "                                          visibility  \n",
       "0  [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, ...  \n",
       "1  [1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, ...  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, ...  \n",
       "4  [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, ...  \n",
       "5  [1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "6  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "7  [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, ...  \n",
       "8  [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove empty entries when training with a single animal\n",
    "out_df.drop(out_df.index[remove_empty_entries], inplace=True)\n",
    "# reset the indices of the updated dataframe\n",
    "out_df.reset_index(drop=True, inplace=True)\n",
    "out_df.to_hdf(os.path.join(target_dir, \"Data_3D_Pose.hdf5\"),\"df_with_missing\",mode=\"w\")\n",
    "\n",
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done!\n"
     ]
    }
   ],
   "source": [
    "# and finally, dump all the labels into a lookup table\n",
    "with open(os.path.join(target_dir,'label_names.txt'), 'w') as f:\n",
    "    # skip first for, and use only every 5th element\n",
    "    for label in labels[4::5]:\n",
    "        if exclude_wings:\n",
    "            if label[0] == \"w\":\n",
    "                continue\n",
    "        f.write(label.split(\".\")[0]+\"\\n\")\n",
    "\n",
    "print(\"All done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that the dataset is generated, let's run a few checks to see if the data contains what we need\n",
    "\n",
    "We'll start off by creating a 3D scatter plot of an example sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def set_axes_equal(ax):\n",
    "    '''Make axes of 3D plot have equal scale so that spheres appear as spheres,\n",
    "    cubes as cubes, etc..  This is one possible solution to Matplotlib's\n",
    "    ax.set_aspect('equal') and ax.axis('equal') not working for 3D.\n",
    "    \n",
    "    Function based on https://stackoverflow.com/questions/13685386/\n",
    "    matplotlib-equal-unit-length-with-equal-aspect-ratio-z-axis-is-not-equal-to\n",
    "\n",
    "    Input\n",
    "      ax: a matplotlib axis, e.g., as output from plt.gca().\n",
    "    '''\n",
    "\n",
    "    x_limits = ax.get_xlim3d()\n",
    "    y_limits = ax.get_ylim3d()\n",
    "    z_limits = ax.get_zlim3d()\n",
    "\n",
    "    x_range = abs(x_limits[1] - x_limits[0])\n",
    "    x_middle = np.mean(x_limits)\n",
    "    y_range = abs(y_limits[1] - y_limits[0])\n",
    "    y_middle = np.mean(y_limits)\n",
    "    z_range = abs(z_limits[1] - z_limits[0])\n",
    "    z_middle = np.mean(z_limits)\n",
    "\n",
    "    # The plot bounding box is a sphere in the sense of the infinity\n",
    "    # norm, hence I call half the max range the plot radius.\n",
    "    plot_radius = 0.5*max([x_range, y_range, z_range])\n",
    "\n",
    "    ax.set_xlim3d([x_middle - plot_radius, x_middle + plot_radius])\n",
    "    ax.set_ylim3d([y_middle - plot_radius, y_middle + plot_radius])\n",
    "    ax.set_zlim3d([z_middle - plot_radius, z_middle + plot_radius])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# to open plot externally and use it interactively\n",
    "show_entry = 0\n",
    "cam_entry = 0\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "display_points_3D = out_df.loc[show_entry][\"key_points_3D\"]\n",
    "display_img = cv2.imread(dataset_img[show_entry])\n",
    "\n",
    "for i,xyz in enumerate(display_points_3D):\n",
    "    if out_df.loc[show_entry][\"visibility\"][i] == 1:\n",
    "        ax.scatter(xyz[0], xyz[1], xyz[2], marker='o',s=10)\n",
    "\n",
    "\"\"\"\n",
    "# also plot the camera location\n",
    "ax.scatter(out_df.loc[cam_entry][\"cam_trans\"][0], \n",
    "           out_df.loc[cam_entry][\"cam_trans\"][1], \n",
    "           out_df.loc[cam_entry][\"cam_trans\"][2], marker='x')\n",
    "\"\"\"\n",
    "\n",
    "ax.set_xlabel('X axis')\n",
    "ax.set_ylabel('Y axis')\n",
    "ax.set_zlabel('Z axis')\n",
    "\n",
    "# use custom function to ensure equal axis proportions\n",
    "set_axes_equal(ax)\n",
    "\n",
    "# opens external plot\n",
    "plt.title(out_df.loc[show_entry][\"file_name\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%matplotlib qt\n",
    "# file_name\tcam_rot\tcam_trans\tcam_intrinsics\tbounding_box\tkey_points_3D\tkey_points_2D\tvisibility\n",
    "R = np.array(out_df.loc[cam_entry][\"cam_rot\"])\n",
    "T = np.reshape(np.array(out_df.loc[cam_entry][\"cam_trans\"]),(3,1))\n",
    "C = np.array(out_df.loc[cam_entry][\"cam_intrinsics\"])\n",
    "\n",
    "#plt.plot(X_2d[0, :], X_2d[1, :], '.')  # plot the locations of the 3D keypoints in 2D as viewed from the camera\n",
    "#plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "for i, x in enumerate(display_points_3D):\n",
    "    X = np.reshape(np.array(out_df.loc[show_entry][\"key_points_3D\"][i]),(3,-1))\n",
    "\n",
    "    # given the above data, it should be possible to project the 3D points into the corresponding image,\n",
    "    # so they land in the correct position on the image \n",
    "    P = C @ np.hstack([R, T])  # projection matrix\n",
    "    X_hom = np.vstack([X, np.ones(X.shape[1])])  # 3D points in homogenous coordinates\n",
    "\n",
    "    X_hom = P @ X_hom  # project the 3D points\n",
    "    \n",
    "    X_2d = X_hom[:2, :] / X_hom[2, :]  # convert them back to 2D pixel space\n",
    "    \n",
    "    gt_x_2d = out_df.loc[show_entry][\"key_points_2D\"][i][0]\n",
    "    gt_y_2d = out_df.loc[show_entry][\"key_points_2D\"][i][1]\n",
    "    \n",
    "    ax.scatter(gt_x_2d, gt_y_2d, marker='o', s=10)\n",
    "    ax.scatter(X_2d[0], display_img.shape[1]-X_2d[1], marker='^', s=2)\n",
    "\n",
    "ax.set_xlabel('X axis')\n",
    "ax.set_ylabel('Y axis')\n",
    "\n",
    "ax.set_xlim([0,display_img.shape[0]])\n",
    "ax.set_ylim([0,display_img.shape[1]])\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# opens external plot\n",
    "plt.title(out_df.loc[show_entry][\"file_name\"] + \"_projected\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
