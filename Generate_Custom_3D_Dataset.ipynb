{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This script is used to automatically generate custom datasets to support object detection as well as 3D and 2D pose estimation, including camera data.\n",
    "\n",
    "**WARNING :** In this version, restrict the **Colony size** to a **maxmimum of 1 indivudal**!\n",
    "\n",
    "Ensure, that your **GPU** has sufficient **memory** for the chosen resolution! \n",
    "\n",
    "The script **excludes empty samples** (*no detections present*) automatically and provide an additional **occlusion vector**, indicating whether a key point is visible (1) or occluded (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 files...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'J:/Output_3D_pose_640_px_single_sungaya/ColonieInfo.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1b73c030dce4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m          'scale': []}\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_colony\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcolony_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"reading\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# pass the file object to reader() to get the reader object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'J:/Output_3D_pose_640_px_single_sungaya/ColonieInfo.csv'"
     ]
    }
   ],
   "source": [
    "# define location of dataset and return all files\n",
    "dataset_location = \"J:/Output_3D_pose_640_px_single_sungaya\"\n",
    "target_dir = \"I:/FARTS/3D_pose_640_px_single_sungaya\"\n",
    "all_files = [f for f in listdir(dataset_location) if isfile(join(dataset_location, f))]\n",
    "\n",
    "# next, sort files into images, depth maps, segmentation maps, data, and colony info\n",
    "dataset_img = []\n",
    "dataset_depth = []\n",
    "dataset_seg = []\n",
    "dataset_data = []\n",
    "dataset_colony = dataset_location + \"/ColonieInfo.csv\"\n",
    "\n",
    "for file in all_files:\n",
    "    loc = dataset_location + \"/\" + file\n",
    "    if file[-7:-4] == \"Img\":\n",
    "        dataset_img.append(loc)\n",
    "    elif file[-7:-4] == \"Seg\":\n",
    "        dataset_seg.append(loc)\n",
    "    elif file[-8:-4] == \"Depth\":\n",
    "        dataset_depth.append(loc)\n",
    "    elif file[-8:-4] == \"Data\":\n",
    "        dataset_data.append(loc)\n",
    "        \n",
    "print(\"Found\",len(all_files),\"files...\")\n",
    "\n",
    "# next sort the colony info into its IDs to determine the colony size and individual scales\n",
    "# one entry for each successive ID is read\n",
    "from csv import reader\n",
    "\n",
    "colony = {'seed': 0,\n",
    "            'ID': [],\n",
    "         'scale': []}\n",
    "\n",
    "with open(dataset_colony, 'r') as colony_file:\n",
    "        print(\"reading\", file)\n",
    "        # pass the file object to reader() to get the reader object\n",
    "        csv_reader = reader(colony_file)\n",
    "        # iterate over each row in the csv using reader object\n",
    "        for r, row in enumerate(csv_reader):\n",
    "            if r == 0:\n",
    "                colony['seed'] = row[0].split(\"=\")[-1]\n",
    "            else:\n",
    "                colony['ID'].append(row[0].split(\"=\")[-1])\n",
    "                colony['scale'].append(row[1].split(\"=\")[-1])\n",
    "\n",
    "print(\"Loaded colony file with seed\",colony['seed'],\"and\",len(colony['ID']),\"individual(s).\")\n",
    "if len(colony['ID']) == 1:\n",
    "    multi_animal = False\n",
    "    print(\"Generating single-animal dataset!\")\n",
    "else:\n",
    "    multi_animal = True\n",
    "    print(\"Generating multi-animal dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the cleaned colony info, we can start loading the data associated with each frame.\n",
    "For simplicity, we will produce a list of lists, containing all individuals and their attributes for each frame.\n",
    "\n",
    "We will therefore access \"data\" as **[frame] [individual] [attribute]**, where attributes will include [ID,bbox_x_0,bbox_y_0,...]\n",
    "\n",
    "The data files additionally contain **camera information**, such as **transformation**, **rotation**, and **intrinsics**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "camera_data = []\n",
    "\n",
    "# get the types of camera information stored\n",
    "camera_data_types = []\n",
    "with open(dataset_data[0], 'r') as read_obj:\n",
    "    csv_reader = reader(read_obj)\n",
    "    for row in csv_reader:\n",
    "        # check if the line contains camera or individual data\n",
    "        if row[0][:3] == \"cam\":\n",
    "            for elem in row:\n",
    "                camera_data_types.append(elem.split(\"=\")[0])\n",
    "\n",
    "for file in dataset_data:\n",
    "    # store all returned coordinates for each individual\n",
    "    coords = []\n",
    "    camera_attributes = []    \n",
    "    # open file in read mode\n",
    "    with open(file, 'r') as read_obj:\n",
    "        #print(\"reading\", file)\n",
    "        # pass the file object to reader() to get the reader object\n",
    "        csv_reader = reader(read_obj)\n",
    "        # iterate over each row in the csv using reader object\n",
    "        for row in csv_reader:\n",
    "            # check if the line contains camera or individual data\n",
    "            camera_attributes = []\n",
    "            if row[0][:3] == \"cam\":\n",
    "                for elem in row:\n",
    "                    try:\n",
    "                        camera_attributes.append(float(elem.split(\"=\")[-1]))\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "                camera_data.append(camera_attributes)\n",
    "                \n",
    "            else:\n",
    "                individual = [float(row[0].split(\".\")[0])]\n",
    "                # row variable is a list that represents a row in csv\n",
    "                for elem in row:\n",
    "                    try:\n",
    "                        individual.append(float(elem.split(\"=\")[-1]))\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "                coords.append(individual)\n",
    "        \n",
    "    data.append(coords)\n",
    "\n",
    "# now let's quickly return if the dataset contains what we were looking for    \n",
    "print(\"\\nThe dataset has a total of\", len(data),\"generated frames.\\n\")\n",
    "\n",
    "if len(camera_data) != 0:\n",
    "    print(\"Found camera data for the following attributes:\\n\",camera_data_types,\"\\n\")\n",
    "    print(\"example camera data of\",dataset_data[0].split(\"/\")[-1],\":\\n\",camera_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there may be animals for which we don't use all bones we can return a list of all labels and exclude the respective locations from the pose data. As all animals use the same convention, we can simply read in one example and remove the corresponding indices from all animals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first open and read the first line from the first imported data file\n",
    "labels = []\n",
    "entries_found = False\n",
    "entry = 0\n",
    "\n",
    "while not entries_found:\n",
    "    with open(dataset_data[entry], 'r') as read_obj:\n",
    "        print(\"reading\", read_obj.name)\n",
    "        # pass the file object to reader() to get the reader object\n",
    "        csv_reader = reader(read_obj)\n",
    "        row_0 = next(csv_reader)  # gets the first line\n",
    "        # iterate over each row in the csv using reader object\n",
    "        if row_0[0][:3] != \"cam\":\n",
    "            entries_found = True\n",
    "            for elem in row_0:\n",
    "                try:\n",
    "                    labels.append((elem.split(\"=\")[0].split(\"Bone.\")[-1]))\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        else:\n",
    "            print(\"No entries found! Reading next file... \\n\")\n",
    "            entry += 1\n",
    "\n",
    "# show all used labels:\n",
    "print(\"\\nAll labels:\")\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded data and colony info we can start plotting bounding boxes, joint locations, and check if the camera attributes have been exported correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform between sRGB and linear colour space (optional)\n",
    "\n",
    "def to_linear(srgb):\n",
    "    linear = np.float32(srgb) / 255.0\n",
    "    less = linear <= 0.04045\n",
    "    linear[less] = linear[less] / 12.92\n",
    "    linear[~less] = np.power((linear[~less] + 0.055) / 1.055, 2.4)\n",
    "    return linear * 255.0\n",
    "\n",
    "    \n",
    "def from_linear(linear):\n",
    "    srgb = linear.copy()\n",
    "    less = linear <= 0.0031308\n",
    "    srgb[less] = linear[less] * 12.92\n",
    "    srgb[~less] = 1.055 * np.power(linear[~less], 1.0 / 2.4) - 0.055\n",
    "    return srgb * 255.0\n",
    "\n",
    "# and compute the XYZ rotation matrix from roll, pitch, and yaw\n",
    "def get_rotation_matrix(roll,pitch,yaw,degrees=True):\n",
    "    # convert to radian\n",
    "    if degrees:\n",
    "        roll = np.radians(roll)\n",
    "        pitch = np.radians(pitch)\n",
    "        yaw = np.radians(yaw)\n",
    "    # roll rotation \n",
    "    Rx = np.array([[1, 0, 0],\n",
    "                   [0,np.cos(roll),-np.sin(roll)],\n",
    "                   [0,np.sin(roll),np.cos(roll)]])\n",
    "    # pitch rotation\n",
    "    Ry = np.array([[np.cos(pitch),0,np.sin(pitch)],\n",
    "                   [0, 1, 0],\n",
    "                   [-np.sin(pitch),0,np.cos(pitch)]])\n",
    "    # yaw rotation\n",
    "    Rz = np.array([[np.cos(yaw),-np.sin(yaw),0],\n",
    "                   [np.sin(yaw),np.cos(yaw),0],\n",
    "                   [0, 0, 1]])\n",
    "    Rxyz = np.round(np.matmul(np.matmul(Rx,Ry),Rz),3)\n",
    "    return Rxyz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating 3D pose output files\n",
    "Now comes the difficult part: getting all this data into the required format.\n",
    "\n",
    "We're going to want an **.h5** formatted file, essentially one dataframe for the entire dataset with the following entries:\n",
    "\n",
    "*\t  file_name &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1 string (relative)\n",
    "*\t  rot_mat\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3 x 3 float\n",
    "*\t  trans_mat\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3 x 1 float\n",
    "*\t  intrinsics_mat &nbsp;&nbsp;&nbsp; 3 x 3 float\n",
    "*     bounding_box &nbsp;&nbsp;&nbsp; 4 x 1 float\n",
    "*\t  key_points_3D &nbsp;&nbsp;&nbsp;3 x k float (provide name sheet)\n",
    "*\t  key_points_2D &nbsp;&nbsp;&nbsp;2 x k float\n",
    "*\t  visibility &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1 x k int (0 occluded or 1 visible)\n",
    "\n",
    "To provide visibility info, we will check whether the subject is visbile in the respective segmentation map at the given screen X & Y coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a big dictionary to store all our dataset info and\n",
    "# save it all to the desired .csv and .h5 files\n",
    "\n",
    "out_df = pd.DataFrame(index=range(len(data)),columns=[\"file_name\",\n",
    "                                                      \"cam_rot\",\n",
    "                                                      \"cam_trans\",\n",
    "                                                      \"cam_intrinsics\",\n",
    "                                                      \"bounding_box\",\n",
    "                                                      \"key_points_3D\",\n",
    "                                                      \"key_points_2D\",\n",
    "                                                      \"visibility\"])\n",
    "#\t- scorer   #(just one, the only scorer is the generator)\n",
    "#\t- - individuals\n",
    "#\t- - - bodyparts\n",
    "#\t- - - - coords\n",
    "\n",
    "print(\"Number of loaded samples:\",len(data))\n",
    "print(\"Colony size:\",len(colony['ID']))\n",
    "print(\"body parts:\",int((len(labels)-4)/5),\" (including image X & Y, as well as world X Y Z coordinates)\\n\")\n",
    "print(\"Resulting in a dataframe of shape:\",out_df.shape)\n",
    "\n",
    "output_file_names = [\"\" for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create unique colours for each ID\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# alright. Let's take it from the top and fucking multi-thread this.\n",
    "import threading\n",
    "import queue\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def fix_bounding_boxes(coords,max_val = [1024,1024]):\n",
    "    # fix bounding box coordinates so they do not reach beyond the image\n",
    "    fixed_coords = []\n",
    "    for c, coord in enumerate(coords):\n",
    "        if c == 0 or c == 2:\n",
    "            max_val_temp = max_val[0]\n",
    "        else:\n",
    "            max_val_temp = max_val[1]\n",
    "            \n",
    "        if coord >= max_val_temp:\n",
    "            coord = max_val_temp\n",
    "        elif coord <= 0:\n",
    "            coord = 0\n",
    "        \n",
    "        fixed_coords.append(int(coord))\n",
    "        \n",
    "    return fixed_coords\n",
    "\n",
    "def getThreads():\n",
    "    \"\"\" Returns the number of available threads on a posix/win based system \"\"\"\n",
    "    if sys.platform == 'win32':\n",
    "        return int(os.environ['NUMBER_OF_PROCESSORS'])\n",
    "    else:\n",
    "        return int(os.popen('grep -c cores /proc/cpuinfo').read())\n",
    "\n",
    "class exportThread(threading.Thread):\n",
    "    def __init__(self, threadID, name, q):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.threadID = threadID\n",
    "        self.name = name\n",
    "        self.q = q\n",
    "\n",
    "    def run(self):\n",
    "        print(\"Starting \" + self.name)\n",
    "        process_detections(self.name, self.q)\n",
    "        print(\"Exiting \" + self.name)\n",
    "        \n",
    "def createThreadList(num_threads):\n",
    "    threadNames = []\n",
    "    for t in range(num_threads):\n",
    "        threadNames.append(\"Thread_\" + str(t))\n",
    "\n",
    "    return threadNames\n",
    "\n",
    "def process_detections(threadName, q):\n",
    "    while not exitFlag_export:\n",
    "        queueLock.acquire()\n",
    "        if not workQueue_export.empty():\n",
    "            \n",
    "            data_input = q.get()\n",
    "            i = data_input[0]\n",
    "            img = data_input[1]\n",
    "            queueLock.release()\n",
    "            \n",
    "            display_img = cv2.imread(img)\n",
    "            display_img_orig = display_img.copy()\n",
    "            \n",
    "            img_shape = display_img.shape\n",
    "            \n",
    "            img_name = target_dir + \"/\" + img.split('/')[-1][:-4] + \"_synth\" + \".png\"\n",
    "            # write the file path to the all_points array\n",
    "            output_file_names[i] = img_name\n",
    "            out_df.loc[i][\"file_name\"] = img_name\n",
    "\n",
    "            img_info = []\n",
    "                \n",
    "            # compute visibility for each individual\n",
    "            seg_img = cv2.imread(dataset_seg[i])\n",
    "            seg_img_display = seg_img.copy()\n",
    "            \n",
    "            # set the default visibility to zero to exclude emtpy images\n",
    "            out_df.loc[i][\"visibility\"] = []\n",
    "\n",
    "            for im, individual in enumerate(data[i]):\n",
    "                \n",
    "                bbox = fix_bounding_boxes(individual[1:5],max_val=display_img.shape)\n",
    "                out_df.loc[i][\"bounding_box\"] = bbox\n",
    "                    \n",
    "                # FOR SOME REASON OCCASIONALLY THE ID OF THE SEG FILE IS LOWER THAN THE DATA FILE\n",
    "                # with: ID = red_channel/255 * im\n",
    "                # red_channel = (ID/im) * 255\n",
    "                ID_red_val = int((individual[0]/len(colony['ID']))*255)\n",
    "                \n",
    "                try:\n",
    "                    ID_mask = cv2.inRange(seg_img[bbox[1]:bbox[3],bbox[0]:bbox[2]], np.array([0,0, ID_red_val - 2]), np.array([0,0, ID_red_val + 2]))\n",
    "                    indivual_occupancy = cv2.countNonZero(ID_mask)\n",
    "                except:\n",
    "                    indivual_occupancy = 1\n",
    "\n",
    "                #indivual_occupancy = np.count_nonzero((seg_img == [0, 0, int((individual[0]/len(colony['ID']))*255)]).all(axis = 2)) + np.count_nonzero((seg_img == [0, 0, int((individual[0]/len(colony['ID']))*255 - 1)]).all(axis = 2)) + np.count_nonzero((seg_img == [0, 0, int((individual[0]/len(colony['ID']))*255 + 1)]).all(axis = 2))\n",
    "                bbox_area = abs((bbox[2] - bbox[0]) * (bbox[3] - bbox[1])) + 1\n",
    "                bbox_occupancy = indivual_occupancy / bbox_area\n",
    "                #print(\"Individual\", individual[0], \"with bounding box occupancy \",bbox_occupancy)\n",
    "                \n",
    "                # write all camera attributes to the output file\n",
    "                # for details, refer to https://ksimek.github.io/2013/08/13/intrinsic/\n",
    "\n",
    "                out_df.loc[i][\"cam_trans\"] = camera_data[i][0:3]\n",
    "                out_df.loc[i][\"cam_rot\"] = get_rotation_matrix(roll=camera_data[i][3],\n",
    "                                                               pitch=camera_data[i][4],\n",
    "                                                               yaw=camera_data[i][5])\n",
    "                out_df.loc[i][\"cam_intrinsics\"] = np.array([[camera_data[i][6],0,camera_data[i][8]],\n",
    "                                                            [0, camera_data[i][7],camera_data[i][9]],\n",
    "                                                            [0,0,1]])\n",
    "\n",
    "                \n",
    "                visbility_img = []\n",
    "                XY_2D_points = []\n",
    "                XYZ_3D_points = []\n",
    "                \n",
    "                #cv2.putText(display_img, \"ID: \" + str(int(individual[0])), (bbox[0] + 10,bbox[3] - 10), font, fontScale, fontColor, lineType)\n",
    "                if bbox_occupancy > visibility_threshold:\n",
    "                    # let's binarise the image and dilate it to make sure all points that visible are found\n",
    "                    seg_bin = cv2.inRange(seg_img, np.array([0,0, ID_red_val - 2]), np.array([0,245, ID_red_val + 2]))\n",
    "                    kernel = np.ones((5,5),np.uint8)\n",
    "                    seg_bin_dilated = cv2.dilate(seg_bin,kernel,iterations = 1)\n",
    "                    \n",
    "                    \n",
    "                    for point in range(int(len(individual[5:])/5)):\n",
    "                        if exclude_wings:\n",
    "                            if labels[3 + point*5][0] == \"w\":\n",
    "                                # skip all entries containing wing data\n",
    "                                continue\n",
    "                                \n",
    "                        if individual[point*5 + 5] > img_shape[0] or individual[point*5 + 5] < 0 or individual[point*5 + 6] > img_shape[1] or individual[point*5 + 6] < 0:\n",
    "                            # exclude all points that lie outside the image\n",
    "                            visibility_point = 0\n",
    "                            XY_2D_points.append([0,0])\n",
    "                            XYZ_3D_points.append([0,0,0])\n",
    "                        else:\n",
    "                            # check if the 2D point is occluded in the segmentation image\n",
    "                            # thanks opencv, of course this has to be indexed as Y,X... thanks, really.\n",
    "                            if seg_bin_dilated[int(individual[6 + point*5]),int(individual[5 + point*5])] == 255:                   \n",
    "                                visibility_point = 1\n",
    "                                XY_2D_points.append(np.array(individual[5 + point*5 : 7 + point*5]).astype(int))\n",
    "                                XYZ_3D_points.append(np.round(individual[7 + point*5 : 10 + point*5],3))\n",
    "                                \n",
    "                                # draw 2D points for visualisation\n",
    "                                if len(threadList_export) == 1:\n",
    "                                    seg_img_display = cv2.circle(seg_img_display, (int(individual[5 + point*5]),\n",
    "                                                                                   int(individual[6 + point*5])), \n",
    "                                                                                   radius=0, color=(255, 100, 100), \n",
    "                                                                                   thickness=5)\n",
    "                            else:\n",
    "                                visibility_point = 0\n",
    "                                XY_2D_points.append([0,0])\n",
    "                                XYZ_3D_points.append([0,0,0])\n",
    "                        \n",
    "                        visbility_img.append(visibility_point)\n",
    "                        \n",
    "                if len(threadList_export) == 1:       \n",
    "                    cv2.imshow(\"Segmentation and points\", seg_img_display)\n",
    "                    cv2.imshow(\"Segmentation binarised and dilated\", seg_bin_dilated)\n",
    "                    cv2.waitKey(0) \n",
    "\n",
    "                out_df.loc[i][\"visibility\"] = visbility_img\n",
    "            \n",
    "            # if no entries were found for the respective image, remove it from the output list and don't write out the image\n",
    "            if len(data[i]) == 0 or len(out_df.loc[i][\"visibility\"]) == 0:\n",
    "                remove_empty_entries.append(i)\n",
    "            else:    \n",
    "                out_df.loc[i][\"key_points_2D\"] = XY_2D_points\n",
    "                out_df.loc[i][\"key_points_3D\"] = XYZ_3D_points\n",
    "                cv2.imwrite(img_name, display_img)\n",
    "            \n",
    "        else:\n",
    "            queueLock.release()\n",
    "            \n",
    "# setup as many threads as there are (virtual) CPU cores\n",
    "exitFlag_export = 0\n",
    "# set the following to 1 (instead of getThreads()) to display segmentation maps and visible key points\n",
    "threadList_export = createThreadList(1)#getThreads())\n",
    "print(\"Using\", len(threadList_export), \"threads for export...\")\n",
    "queueLock = threading.Lock()\n",
    "\n",
    "# define paths to all images and set the maximum number of items in the queue equivalent to the number of images\n",
    "workQueue_export = queue.Queue(len(dataset_img))\n",
    "threads = []\n",
    "threadID = 1\n",
    "\n",
    "np.random.seed(seed=1)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 0.5\n",
    "lineType = 2\n",
    "\n",
    "# remove entries that contain no data\n",
    "remove_empty_entries = []\n",
    "\n",
    "# set true if generating dataset for animal without wings\n",
    "exclude_wings = True\n",
    "\n",
    "# we can additionally plot the points in the data files to check joint locations\n",
    "plot_joints = True\n",
    "\n",
    "# remember to refine an export folder when saving out your dataset\n",
    "generate_dataset = True\n",
    "\n",
    "# determine the proportion of a bounding box that needs to be filled before considering the visibility as too low\n",
    "# WARNING: At the moment the ID shown in segmentation maps does not always correspond to the ID in the data file (off by 1)\n",
    "visibility_threshold = 0.001\n",
    "\n",
    "timer = time.time()\n",
    "\n",
    "# Create new threads\n",
    "for tName in threadList_export:\n",
    "    thread = exportThread(threadID, tName, workQueue_export)\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "    threadID += 1\n",
    "\n",
    "# Fill the queue with stacks\n",
    "queueLock.acquire()\n",
    "for i,img in enumerate(dataset_img):\n",
    "    workQueue_export.put([i, img])\n",
    "queueLock.release()\n",
    "\n",
    "# Wait for queue to empty\n",
    "while not workQueue_export.empty():\n",
    "    pass\n",
    "\n",
    "# Notify threads it's time to exit\n",
    "exitFlag_export = 1\n",
    "\n",
    "# Wait for all threads to complete\n",
    "for t in threads:\n",
    "    t.join()\n",
    "print(\"Exiting Main export Thread\")\n",
    "\n",
    "# close all windows if they were opened\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Total time elapsed:\",time.time()-timer,\"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, remove empty entries and dump it all into one **.h5** file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty entries when training with a single animal\n",
    "out_df.drop(out_df.index[remove_empty_entries], inplace=True)\n",
    "# reset the indices of the updated dataframe\n",
    "out_df.reset_index(drop=True, inplace=True)\n",
    "out_df.to_hdf(os.path.join(target_dir, \"Data_3D_Pose.hdf5\"),\"df_with_missing\",mode=\"w\")\n",
    "\n",
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and finally, dump all the labels into a lookup table\n",
    "with open(os.path.join(target_dir,'label_names.txt'), 'w') as f:\n",
    "    # skip first for, and use only every 5th element\n",
    "    for label in labels[4::5]:\n",
    "        if exclude_wings:\n",
    "            if label[0] == \"w\":\n",
    "                continue\n",
    "        f.write(label.split(\".\")[0]+\"\\n\")\n",
    "\n",
    "print(\"All done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
